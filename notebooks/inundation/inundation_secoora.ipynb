{
 "metadata": {
  "name": "",
  "signature": "sha256:9f14ed9de3d2503878215ed96432d99a151b69d5bc2a272faf45955aef72e2c3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Standard Library.\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "from datetime import datetime, timedelta\n",
      "\n",
      "# Scientific stack.\n",
      "import iris\n",
      "iris.FUTURE.netcdf_promote = True\n",
      "from iris.pandas import as_series\n",
      "from iris.exceptions import CoordinateNotFoundError, CoordinateMultiDimError\n",
      "\n",
      "import folium\n",
      "import vincent\n",
      "import numpy as np\n",
      "from pandas import Series, DataFrame, read_csv\n",
      "\n",
      "from owslib import fes\n",
      "from owslib.csw import CatalogueServiceWeb\n",
      "from pyoos.collectors.coops.coops_sos import CoopsSos\n",
      "\n",
      "# Local imports.\n",
      "from utilities import (dateRange, get_coops_longname, coops2df, make_tree,\n",
      "                       get_coordinates, get_model_name, get_nearest_water,\n",
      "                       service_urls, slice_bbox_extract, plt_grid, get_cube)"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [],
      "input_collapsed": false
     },
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "now = datetime.utcnow()\n",
      "\n",
      "start = now - timedelta(days=3)\n",
      "stop = now + timedelta(days=3)\n",
      "\n",
      "start_date = start.strftime('%Y-%m-%d %H:00')\n",
      "stop_date = stop.strftime('%Y-%m-%d %H:00')\n",
      "\n",
      "jd_start = datetime.strptime(start_date, '%Y-%m-%d %H:%M')\n",
      "jd_stop = datetime.strptime(stop_date, '%Y-%m-%d %H:%M')\n",
      "\n",
      "print('%s to %s' % (start_date, stop_date))"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-07-17 18:00 to 2014-07-23 18:00\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "name_list = ['water level',\n",
      "             'sea_surface_height',\n",
      "             'sea_surface_elevation',\n",
      "             'sea_surface_height_above_geoid',\n",
      "             'sea_surface_height_above_sea_level',\n",
      "             'water_surface_height_above_reference_datum',\n",
      "             'sea_surface_height_above_reference_ellipsoid']\n",
      "\n",
      "bounding_box_type = \"box\"\n",
      "bounding_box = [[-87.4, 24.25],\n",
      "                [-74.7, 36.70]]  # SECOORA: NC, SC GA, FL\n",
      "\n",
      "box = []\n",
      "box.append(bounding_box[0][0])\n",
      "box.append(bounding_box[0][1])\n",
      "box.append(bounding_box[1][0])\n",
      "box.append(bounding_box[1][1])\n",
      "\n",
      "start, stop = dateRange(start_date, stop_date)\n",
      "bbox = fes.BBox(box)\n",
      "\n",
      "or_filt = fes.Or([fes.PropertyIsLike(propertyname='apiso:AnyText',\n",
      "                                     literal=('*%s*' % val),\n",
      "                                     escapeChar='\\\\',\n",
      "                                     wildCard='*',\n",
      "                                     singleChar='?') for val in name_list])\n",
      "\n",
      "val = 'Averages'\n",
      "not_filt = fes.Not([fes.PropertyIsLike(propertyname='apiso:AnyText',\n",
      "                                       literal=('*%s*' % val),\n",
      "                                       escapeChar='\\\\',\n",
      "                                       wildCard='*',\n",
      "                                       singleChar='?')])\n",
      "\n",
      "filter_list = [fes.And([bbox, start, stop, or_filt, not_filt])]"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "endpoint = 'http://www.ngdc.noaa.gov/geoportal/csw'\n",
      "csw = CatalogueServiceWeb(endpoint, timeout=60)\n",
      "csw.getrecords2(constraints=filter_list, maxrecords=1000, esn='full')\n",
      "\n",
      "if True:\n",
      "    print(\"CSW version: %s\" % csw.version)\n",
      "    print(\"Number of datasets available: %s\" % len(csw.records.keys()))"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CSW version: 2.0.2\n",
        "Number of datasets available: 11\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dap_urls = service_urls(csw.records, service='odp:url')\n",
      "sos_urls = service_urls(csw.records, service='sos:url')\n",
      "\n",
      "if True:\n",
      "    print(\"CSW:\")\n",
      "    for rec, item in csw.records.items():\n",
      "        print(item.title)\n",
      "    print(\"\\nDAP:\")\n",
      "    print(\"\\n\".join(dap_urls))\n",
      "    print(\"\\nSOS:\")\n",
      "    print(\"\\n\".join(sos_urls))"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CSW:\n",
        "ROMS/TOMS 3.0 - South-Atlantic Bight and Gulf of Mexico\n",
        "COAWST Forecast System : USGS : US East Coast and Gulf of Mexico (Experimental)\n",
        "ROMS ESPRESSO Real-Time Operational IS4DVAR Forecast System Version 2 (NEW) 2013-present FMRC History (Best)\n",
        "Barotropic Tide Model for the Pacific Basin\n",
        "TBOFS - Tampa Bay Operational Forecast System - NOAA CO-OPS - POM\n",
        "NDBC Standard Meteorological Buoy Data\n",
        "HYbrid Coordinate Ocean Model (HYCOM): Global\n",
        "CBOFS - Chesapeake Bay Operational Forecast System - NOAA CO-OPS - POM\n",
        "ESTOFS Storm Surge Model - Atlantic - v1.0.0 - NOAA - NCEP - ADCIRC\n",
        "NECOFS GOM3 (FVCOM) - Northeast US - Latest Forecast\n",
        "NECOFS GOM3 Wave - Northeast US - Latest Forecast\n",
        "\n",
        "DAP:\n",
        "http://omgsrv1.meas.ncsu.edu:8080/thredds/dodsC/fmrc/sabgom/SABGOM_Forecast_Model_Run_Collection_best.ncd\n",
        "http://geoport.whoi.edu/thredds/dodsC/coawst_4/use/fmrc/coawst_4_use_best.ncd\n",
        "http://tds.marine.rutgers.edu/thredds/dodsC/roms/espresso/2013_da/his_Best/ESPRESSO_Real-Time_v2_History_Best_Available_best.ncd\n",
        "http://oos.soest.hawaii.edu/thredds/dodsC/hioos/tide_pac\n",
        "http://opendap.co-ops.nos.noaa.gov/thredds/dodsC/TBOFS/fmrc/Aggregated_7_day_TBOFS_Fields_Forecast_best.ncd\n",
        "http://oos.soest.hawaii.edu/thredds/dodsC/pacioos/hycom/global\n",
        "http://opendap.co-ops.nos.noaa.gov/thredds/dodsC/CBOFS/fmrc/Aggregated_7_day_CBOFS_Fields_Forecast_best.ncd\n",
        "http://geoport-dev.whoi.edu/thredds/dodsC/estofs/atlantic\n",
        "http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc\n",
        "http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_WAVE_FORECAST.nc\n",
        "\n",
        "SOS:\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collector = CoopsSos()\n",
      "sos_name = 'water_surface_height_above_reference_datum'\n",
      "\n",
      "collector.set_datum('NAVD')\n",
      "collector.end_time = jd_stop\n",
      "collector.start_time = jd_start\n",
      "collector.variables = [sos_name]\n",
      "\n",
      "ofrs = collector.server.offerings\n",
      "if True:\n",
      "    print(collector.server.identification.title)\n",
      "    print(len(ofrs))"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NOAA.NOS.CO-OPS SOS\n",
        "1028\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iso_start = jd_start.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
      "iso_stop = jd_stop.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
      "box_str = ','.join(str(e) for e in box)\n",
      "\n",
      "print(\"Lat/Lon Box: %s\" % box_str)\n",
      "print(\"Date: %s to %s\" % (iso_start, iso_stop))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Lat/Lon Box: -87.4,24.25,-74.7,36.7\n",
        "Date: 2014-07-17T18:00:00Z to 2014-07-23T18:00:00Z\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = ('http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS?'\n",
      "       'service=SOS&request=GetObservation&version=1.0.0&'\n",
      "       'observedProperty=%s&offering=urn:ioos:network:NOAA.NOS.CO-OPS:'\n",
      "       'WaterLevelActive&featureOfInterest=BBOX:%s&responseFormat='\n",
      "       'text/csv&eventTime=%s' % (sos_name, box_str, iso_start))\n",
      "\n",
      "print(url)\n",
      "observations = read_csv(url)"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS?service=SOS&request=GetObservation&version=1.0.0&observedProperty=water_surface_height_above_reference_datum&offering=urn:ioos:network:NOAA.NOS.CO-OPS:WaterLevelActive&featureOfInterest=BBOX:-87.4,24.25,-74.7,36.7&responseFormat=text/csv&eventTime=2014-07-17T18:00:00Z\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Clean the dataframe."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns = {'station_id': 'station',\n",
      "           'sensor_id': 'sensor',\n",
      "           'datum_id': 'datum',\n",
      "           'latitude (degree)': 'lat',\n",
      "           'longitude (degree)': 'lon',\n",
      "           'vertical_position (m)': 'height',\n",
      "           'water_surface_height_above_reference_datum (m)': 'ssh above datum'}\n",
      "\n",
      "observations.rename(columns=columns, inplace=True)\n",
      "\n",
      "observations['datum'] = [s.split(':')[-1] for s in observations['datum']]\n",
      "observations['sensor'] = [s.split(':')[-1] for s in observations['sensor']]\n",
      "observations['station'] = [s.split(':')[-1] for s in observations['station']]\n",
      "observations['name'] = [get_coops_longname(s) for s in observations['station']]\n",
      "\n",
      "observations.set_index('name', inplace=True)\n",
      "\n",
      "observations.head()"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>station</th>\n",
        "      <th>sensor</th>\n",
        "      <th>lat</th>\n",
        "      <th>lon</th>\n",
        "      <th>date_time</th>\n",
        "      <th>ssh above datum</th>\n",
        "      <th>datum</th>\n",
        "      <th>height</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>name</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Duck, NC</th>\n",
        "      <td> 8651370</td>\n",
        "      <td> A1</td>\n",
        "      <td> 36.1833</td>\n",
        "      <td>-75.7467</td>\n",
        "      <td> 2014-07-17T18:00:00Z</td>\n",
        "      <td> 1.079</td>\n",
        "      <td> MLLW</td>\n",
        "      <td> 5.663</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Oregon Inlet Marina, NC</th>\n",
        "      <td> 8652587</td>\n",
        "      <td> A1</td>\n",
        "      <td> 35.7950</td>\n",
        "      <td>-75.5483</td>\n",
        "      <td> 2014-07-17T18:00:00Z</td>\n",
        "      <td> 0.372</td>\n",
        "      <td> MLLW</td>\n",
        "      <td> 0.788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>USCG Station Hatteras, NC</th>\n",
        "      <td> 8654467</td>\n",
        "      <td> A1</td>\n",
        "      <td> 35.2086</td>\n",
        "      <td>-75.7042</td>\n",
        "      <td> 2014-07-17T18:00:00Z</td>\n",
        "      <td> 0.293</td>\n",
        "      <td> MLLW</td>\n",
        "      <td> 8.345</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Beaufort, NC</th>\n",
        "      <td> 8656483</td>\n",
        "      <td> A1</td>\n",
        "      <td> 34.7200</td>\n",
        "      <td>-76.6700</td>\n",
        "      <td> 2014-07-17T18:00:00Z</td>\n",
        "      <td> 1.129</td>\n",
        "      <td> MLLW</td>\n",
        "      <td> 0.562</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Wilmington, NC</th>\n",
        "      <td> 8658120</td>\n",
        "      <td> A1</td>\n",
        "      <td> 34.2267</td>\n",
        "      <td>-77.9533</td>\n",
        "      <td> 2014-07-17T18:00:00Z</td>\n",
        "      <td> 1.456</td>\n",
        "      <td> MLLW</td>\n",
        "      <td> 0.747</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "                           station sensor      lat      lon  \\\n",
        "name                                                          \n",
        "Duck, NC                   8651370     A1  36.1833 -75.7467   \n",
        "Oregon Inlet Marina, NC    8652587     A1  35.7950 -75.5483   \n",
        "USCG Station Hatteras, NC  8654467     A1  35.2086 -75.7042   \n",
        "Beaufort, NC               8656483     A1  34.7200 -76.6700   \n",
        "Wilmington, NC             8658120     A1  34.2267 -77.9533   \n",
        "\n",
        "                                      date_time  ssh above datum datum  height  \n",
        "name                                                                            \n",
        "Duck, NC                   2014-07-17T18:00:00Z            1.079  MLLW   5.663  \n",
        "Oregon Inlet Marina, NC    2014-07-17T18:00:00Z            0.372  MLLW   0.788  \n",
        "USCG Station Hatteras, NC  2014-07-17T18:00:00Z            0.293  MLLW   8.345  \n",
        "Beaufort, NC               2014-07-17T18:00:00Z            1.129  MLLW   0.562  \n",
        "Wilmington, NC             2014-07-17T18:00:00Z            1.456  MLLW   0.747  "
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Generate a uniform 6-min time base for model/data comparison:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "from owslib.ows import ExceptionReport\n",
      "\n",
      "fname = 'OBS_DATA.csv'\n",
      "if not os.path.isfile(fname):\n",
      "    data = dict()\n",
      "    for s in observations.station:\n",
      "        try:\n",
      "            b = coops2df(collector, s, sos_name)\n",
      "            b = b['water_surface_height_above_reference_datum (m)']\n",
      "            data.update({s: b})\n",
      "        except ExceptionReport as e:\n",
      "            print(\"[%s] %s:\\n%s\" % (s, get_coops_longname(s), e))\n",
      "    obs_data = DataFrame.from_dict(data)\n",
      "    obs_data.to_csv(fname)\n",
      "else:\n",
      "    obs_data = read_csv(fname, parse_dates=True, index_col=0)\n",
      "\n",
      "obs_data.head()"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[8654467] USCG Station Hatteras, NC:\n",
        "'Wrong Datum for this station: The correct Datum values are: MHHW, MHW, MTL, MSL, MLW, MLLW, STND'\n",
        "[8656483] Beaufort, NC:\n",
        "'Wrong Datum for this station: The correct Datum values are: MHHW, MHW, MTL, MSL, MLW, MLLW, STND'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[8658120] Wilmington, NC:\n",
        "'Wrong Datum for this station: The correct Datum values are: MHHW, MHW, MTL, MSL, MLW, MLLW, STND'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[8726520] St Petersburg, FL:\n",
        "'Wrong Datum for this station: The correct Datum values are: MHHW, MHW, MTL, MSL, MLW, MLLW, STND'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[8726607] Old Port Tampa, FL:\n",
        "'Wrong Datum for this station: The correct Datum values are: MHHW, MHW, MTL, MSL, MLW, MLLW, STND'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[8729210] Panama City Beach, FL:\n",
        "'Wrong Datum for this station: The correct Datum values are: MHHW, MHW, MTL, MSL, MLW, MLLW, STND'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>8651370</th>\n",
        "      <th>8652587</th>\n",
        "      <th>8658163</th>\n",
        "      <th>8661070</th>\n",
        "      <th>8662245</th>\n",
        "      <th>8665530</th>\n",
        "      <th>8670870</th>\n",
        "      <th>8720030</th>\n",
        "      <th>8720218</th>\n",
        "      <th>8720219</th>\n",
        "      <th>...</th>\n",
        "      <th>8724580</th>\n",
        "      <th>8725110</th>\n",
        "      <th>8725520</th>\n",
        "      <th>8726384</th>\n",
        "      <th>8726667</th>\n",
        "      <th>8726724</th>\n",
        "      <th>8727520</th>\n",
        "      <th>8728690</th>\n",
        "      <th>8729108</th>\n",
        "      <th>8729840</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>date_time</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2014-07-17 18:00:00</th>\n",
        "      <td> 0.412</td>\n",
        "      <td> 0.157</td>\n",
        "      <td> 0.476</td>\n",
        "      <td> 0.597</td>\n",
        "      <td> 0.832</td>\n",
        "      <td> 0.871</td>\n",
        "      <td> 1.112</td>\n",
        "      <td> 0.937</td>\n",
        "      <td> 0.660</td>\n",
        "      <td> 0.487</td>\n",
        "      <td>...</td>\n",
        "      <td>-0.047</td>\n",
        "      <td>-0.082</td>\n",
        "      <td>-0.047</td>\n",
        "      <td>-0.087</td>\n",
        "      <td>-0.192</td>\n",
        "      <td> 0.106</td>\n",
        "      <td>-0.328</td>\n",
        "      <td>-0.070</td>\n",
        "      <td> 0.098</td>\n",
        "      <td> 0.125</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-07-17 18:06:00</th>\n",
        "      <td> 0.398</td>\n",
        "      <td> 0.153</td>\n",
        "      <td> 0.451</td>\n",
        "      <td> 0.579</td>\n",
        "      <td> 0.819</td>\n",
        "      <td> 0.854</td>\n",
        "      <td> 1.096</td>\n",
        "      <td> 0.931</td>\n",
        "      <td> 0.656</td>\n",
        "      <td> 0.490</td>\n",
        "      <td>...</td>\n",
        "      <td>-0.042</td>\n",
        "      <td>-0.036</td>\n",
        "      <td>-0.051</td>\n",
        "      <td>-0.072</td>\n",
        "      <td>-0.186</td>\n",
        "      <td> 0.105</td>\n",
        "      <td>-0.311</td>\n",
        "      <td>-0.075</td>\n",
        "      <td> 0.096</td>\n",
        "      <td> 0.126</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-07-17 18:12:00</th>\n",
        "      <td> 0.352</td>\n",
        "      <td> 0.151</td>\n",
        "      <td> 0.437</td>\n",
        "      <td> 0.558</td>\n",
        "      <td> 0.805</td>\n",
        "      <td> 0.840</td>\n",
        "      <td> 1.067</td>\n",
        "      <td> 0.926</td>\n",
        "      <td> 0.643</td>\n",
        "      <td> 0.496</td>\n",
        "      <td>...</td>\n",
        "      <td>-0.039</td>\n",
        "      <td>-0.042</td>\n",
        "      <td>-0.056</td>\n",
        "      <td>-0.061</td>\n",
        "      <td>-0.172</td>\n",
        "      <td> 0.109</td>\n",
        "      <td>-0.294</td>\n",
        "      <td>-0.078</td>\n",
        "      <td> 0.099</td>\n",
        "      <td> 0.125</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-07-17 18:18:00</th>\n",
        "      <td> 0.325</td>\n",
        "      <td> 0.150</td>\n",
        "      <td> 0.426</td>\n",
        "      <td> 0.516</td>\n",
        "      <td> 0.789</td>\n",
        "      <td> 0.814</td>\n",
        "      <td> 1.039</td>\n",
        "      <td> 0.917</td>\n",
        "      <td> 0.629</td>\n",
        "      <td> 0.496</td>\n",
        "      <td>...</td>\n",
        "      <td>-0.036</td>\n",
        "      <td>-0.011</td>\n",
        "      <td>-0.058</td>\n",
        "      <td>-0.059</td>\n",
        "      <td>-0.162</td>\n",
        "      <td> 0.102</td>\n",
        "      <td>-0.278</td>\n",
        "      <td>-0.085</td>\n",
        "      <td> 0.099</td>\n",
        "      <td> 0.122</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-07-17 18:24:00</th>\n",
        "      <td> 0.323</td>\n",
        "      <td> 0.145</td>\n",
        "      <td> 0.383</td>\n",
        "      <td> 0.506</td>\n",
        "      <td> 0.772</td>\n",
        "      <td> 0.789</td>\n",
        "      <td> 1.025</td>\n",
        "      <td> 0.902</td>\n",
        "      <td> 0.613</td>\n",
        "      <td> 0.497</td>\n",
        "      <td>...</td>\n",
        "      <td>-0.033</td>\n",
        "      <td>-0.018</td>\n",
        "      <td>-0.064</td>\n",
        "      <td>-0.056</td>\n",
        "      <td>-0.156</td>\n",
        "      <td> 0.121</td>\n",
        "      <td>-0.260</td>\n",
        "      <td>-0.088</td>\n",
        "      <td> 0.100</td>\n",
        "      <td> 0.119</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 28 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "                     8651370  8652587  8658163  8661070  8662245  8665530  \\\n",
        "date_time                                                                   \n",
        "2014-07-17 18:00:00    0.412    0.157    0.476    0.597    0.832    0.871   \n",
        "2014-07-17 18:06:00    0.398    0.153    0.451    0.579    0.819    0.854   \n",
        "2014-07-17 18:12:00    0.352    0.151    0.437    0.558    0.805    0.840   \n",
        "2014-07-17 18:18:00    0.325    0.150    0.426    0.516    0.789    0.814   \n",
        "2014-07-17 18:24:00    0.323    0.145    0.383    0.506    0.772    0.789   \n",
        "\n",
        "                     8670870  8720030  8720218  8720219   ...     8724580  \\\n",
        "date_time                                                 ...               \n",
        "2014-07-17 18:00:00    1.112    0.937    0.660    0.487   ...      -0.047   \n",
        "2014-07-17 18:06:00    1.096    0.931    0.656    0.490   ...      -0.042   \n",
        "2014-07-17 18:12:00    1.067    0.926    0.643    0.496   ...      -0.039   \n",
        "2014-07-17 18:18:00    1.039    0.917    0.629    0.496   ...      -0.036   \n",
        "2014-07-17 18:24:00    1.025    0.902    0.613    0.497   ...      -0.033   \n",
        "\n",
        "                     8725110  8725520  8726384  8726667  8726724  8727520  \\\n",
        "date_time                                                                   \n",
        "2014-07-17 18:00:00   -0.082   -0.047   -0.087   -0.192    0.106   -0.328   \n",
        "2014-07-17 18:06:00   -0.036   -0.051   -0.072   -0.186    0.105   -0.311   \n",
        "2014-07-17 18:12:00   -0.042   -0.056   -0.061   -0.172    0.109   -0.294   \n",
        "2014-07-17 18:18:00   -0.011   -0.058   -0.059   -0.162    0.102   -0.278   \n",
        "2014-07-17 18:24:00   -0.018   -0.064   -0.056   -0.156    0.121   -0.260   \n",
        "\n",
        "                     8728690  8729108  8729840  \n",
        "date_time                                       \n",
        "2014-07-17 18:00:00   -0.070    0.098    0.125  \n",
        "2014-07-17 18:06:00   -0.075    0.096    0.126  \n",
        "2014-07-17 18:12:00   -0.078    0.099    0.125  \n",
        "2014-07-17 18:18:00   -0.085    0.099    0.122  \n",
        "2014-07-17 18:24:00   -0.088    0.100    0.119  \n",
        "\n",
        "[5 rows x 28 columns]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "diff = set(observations['station'].values).difference(obs_data.columns)\n",
      "non_navd = [c not in diff for c in observations['station']]\n",
      "observations = observations[non_navd]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Loop the models and save a csv series at each station."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "name_in_list = lambda cube: cube.standard_name in name_list\n",
      "constraint = iris.Constraint(cube_func=name_in_list, coord_values=None)\n",
      "\n",
      "for url in dap_urls:\n",
      "    # FIXME: NECOFS has cartesian coordinates.\n",
      "    if 'NECOFS' in url:\n",
      "        continue\n",
      "    try:\n",
      "        cube = get_cube(url, constraint, jd_start, jd_stop)\n",
      "    except (RuntimeError, ValueError) as e:\n",
      "        print('Cannot get cube for: %s\\n%s' % (url, e))\n",
      "        continue\n",
      "    try:\n",
      "        cube = cube.intersection(longitude=(bounding_box[0][0],\n",
      "                                            bounding_box[1][0]),\n",
      "                                 latitude=(bounding_box[0][1],\n",
      "                                           bounding_box[1][1]))\n",
      "    except CoordinateMultiDimError:\n",
      "        cube = slice_bbox_extract(cube, bounding_box)\n",
      "\n",
      "    mod_name, model_full_name = get_model_name(cube, url)\n",
      "    print('\\n[%s] %s:\\n%s\\n' % (mod_name, cube.attributes['title'], url))\n",
      "\n",
      "    fname = '%s.csv' % mod_name\n",
      "    if not os.path.isfile(fname):\n",
      "        # Make tree.\n",
      "        try:\n",
      "            tree, lon, lat = make_tree(cube)\n",
      "            fig, ax = plt_grid(lon, lat)\n",
      "        except CoordinateNotFoundError as e:\n",
      "            print('Cannot make KDTree for: %s' % mod_name)\n",
      "            continue\n",
      "        # Get model series at observed locations.\n",
      "        model = dict()\n",
      "        for station, obs in observations.iterrows():\n",
      "            a = obs_data[obs['station']]\n",
      "            try:\n",
      "                kw = dict(k=10, max_dist=0.04, min_var=0.01)\n",
      "                series, dist, idx = get_nearest_water(cube, tree,\n",
      "                                                      obs.lon, obs.lat, **kw)\n",
      "            except ValueError as e:\n",
      "                print(e)\n",
      "                continue\n",
      "            if not series:\n",
      "                status = \"Not Found\"\n",
      "                series = Series(np.empty_like(a) * np.NaN, index=a.index)\n",
      "            else:\n",
      "                series = as_series(series)\n",
      "                status = \"Found\"\n",
      "                ax.plot(lon[idx], lat[idx], 'g.')\n",
      "\n",
      "            print('[%s] %s' % (status, obs.name))\n",
      "\n",
      "            kw = dict(method='time')\n",
      "            series = series.reindex(a.index).interpolate(**kw).ix[a.index]\n",
      "            model.update({obs['station']: series})\n",
      "\n",
      "        model = DataFrame.from_dict(model).dropna(axis=1, how='all')\n",
      "        model.to_csv(fname)\n",
      "\n",
      "        ax.set_title('%s: Points found %s' % (mod_name, len(model.columns)))\n",
      "        ax.plot(observations.lon, observations.lat, 'ro',\n",
      "                zorder=1, label='Observation', alpha=0.25)\n",
      "        ax.set_extent([bounding_box[0][0], bounding_box[1][0],\n",
      "                       bounding_box[0][1], bounding_box[1][1]])"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       3
      ]
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[SABGOM] ROMS/TOMS 3.0 - South-Atlantic Bight and Gulf of Mexico:\n",
        "http://omgsrv1.meas.ncsu.edu:8080/thredds/dodsC/fmrc/sabgom/SABGOM_Forecast_Model_Run_Collection_best.ncd\n",
        "\n",
        "[Found] Duck, NC"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Not Found] Oregon Inlet Marina, NC"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Found] Wrightsville Beach, NC"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Found] Springmaid Pier, SC"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Not Found] Oyster Landing (N Inlet Estuary), SC"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Not Found] Charleston, SC"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Not Found] Fort Pulaski, GA"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Not Found] Fernandina Beach, FL"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Not Found] Mayport (Bar Pilots Dock), FL"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Not Found] Dames Point, FL"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from glob import glob\n",
      "from pandas import Panel\n",
      "\n",
      "dfs = dict()\n",
      "kw = dict(parse_dates=True, index_col=0)\n",
      "for fname in glob('*.csv'):\n",
      "    df = read_csv(fname, **kw)\n",
      "    dfs.update({fname[:-4]: df})\n",
      "\n",
      "dfs = Panel.fromDict(dfs)\n",
      "dfs = dfs.swapaxes(0, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inundation_map = folium.Map(location=[np.mean(bounding_box, axis=0)[1],\n",
      "                                      np.mean(bounding_box, axis=0)[0]],\n",
      "                            zoom_start=5)\n",
      "\n",
      "# Create the map and add the bounding box line.\n",
      "inundation_map.line(get_coordinates(bounding_box, bounding_box_type),\n",
      "                    line_color='#FF0000', line_weight=2)\n",
      "\n",
      "html = '<b>Station:</b><br>%s<br><b>Long Name:</b><br>%s'\n",
      "\n",
      "for station in dfs:\n",
      "    sta_name = get_coops_longname(station)\n",
      "    df = dfs[station].dropna(axis=1, how='all')\n",
      "    # FIXME: This is bad!  But I cannot represent NaN with Vega!\n",
      "    df.fillna(value=0, inplace=True)\n",
      "    vis = vincent.Line(df, width=400, height=200)\n",
      "    vis.axis_titles(x='Time', y='Sea surface height (m)')\n",
      "    vis.legend(title=sta_name)\n",
      "    json = 'station_%s.json' % station\n",
      "    vis.to_json(json)\n",
      "    obs = observations[observations['station'] == station]\n",
      "    inundation_map.simple_marker(location=[obs['lat'].values[0],\n",
      "                                           obs['lon'].values[0]],\n",
      "                                 popup=(vis, json))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inundation_map.create_map(path='inundation_map.html')\n",
      "inundation_map.render_iframe = True\n",
      "inundation_map"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}