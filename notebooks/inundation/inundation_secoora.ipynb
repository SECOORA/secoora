{
 "metadata": {
  "name": "",
  "signature": "sha256:b9adeb9068ae7a3cf6812a2b26f7ce9aae78f8c34fb5b9d792e46e6052742065"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def coops2data(collector,station_id,sos_name):\n",
      "    collector.features = [station_id]\n",
      "    collector.variables = [sos_name]\n",
      "    station_data = dict()\n",
      "    #loop through the years and get the data needed\n",
      "    for year_station in range(int(collector.start_time.year),collector.end_time.year+1):      \n",
      "        link = \"http://tidesandcurrents.noaa.gov/api/datagetter?product=\"+sos_name+\"&application=NOS.COOPS.TAC.WL&\"\n",
      "        date1 = \"begin_date=\"+str(year_station)+\"0101\"\n",
      "        date2 = \"&end_date=\"+str(year_station)+\"1231\"\n",
      "        datum = \"&datum=MHHW\"\n",
      "        units = \"&units=metric\"\n",
      "        station_request = \"&station=\"+station_id+\"&time_zone=GMT&units=english&format=json\"\n",
      "        http_request = link+date1+date2+units+datum+station_request\n",
      "        #print http_request\n",
      "        d_r = requests.get(http_request,timeout=20)\n",
      "        if \"Great Lake station\" in d_r.text:\n",
      "            pass\n",
      "        else:\n",
      "            key_list =  d_r.json().keys()\n",
      "            if \"data\" in key_list:\n",
      "                data = d_r.json()['data']\n",
      "                max_value,num_samples,date_string = findMaxVal(data)\n",
      "                station_data[str(year_station)] =  {\"max\":max_value,\"num_samples\":num_samples,\"date_string\":date_string,\"raw\":data}\n",
      "                #print \"\\tyear:\",year_station,\" MaxValue:\",max_value\n",
      "    return station_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append(\"..\")\n",
      "\n",
      "# Standard Library.\n",
      "from warnings import warn\n",
      "from datetime import datetime, timedelta\n",
      "\n",
      "# Scientific stack.\n",
      "import iris\n",
      "import folium\n",
      "import numpy as np\n",
      "import cartopy.crs as ccrs\n",
      "import matplotlib.pyplot as plt\n",
      "from shapely.geometry import Polygon, Point, LineString\n",
      "from pandas import DataFrame, date_range, read_csv, concat\n",
      "from iris.exceptions import CoordinateNotFoundError, ConstraintMismatchError\n",
      "\n",
      "# Custom IOOS/ASA modules (available at PyPI).\n",
      "from owslib import fes\n",
      "from owslib.csw import CatalogueServiceWeb\n",
      "from pyoos.collectors.coops.coops_sos import CoopsSos\n",
      "\n",
      "# Local imports\n",
      "from utilities import name_list, sos_name\n",
      "from utilities import (find_timevar, find_ij, nearxy,\n",
      "                       dateRange, get_Coops_longName, coops2df,\n",
      "                       mod_df, service_urls, inline_map, get_coordinates)"
     ],
     "language": "python",
     "metadata": {
      "input_collapsed": false
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "now = datetime.utcnow()\n",
      "\n",
      "start = now - timedelta(days=3)\n",
      "stop = now + timedelta(days=3)\n",
      "\n",
      "start_date = start.strftime('%Y-%m-%d %H:00')\n",
      "stop_date = stop.strftime('%Y-%m-%d %H:00')\n",
      "time_date_range = [start_date, stop_date]\n",
      "\n",
      "jd_start = datetime.strptime(start_date, '%Y-%m-%d %H:%M')\n",
      "jd_stop = datetime.strptime(stop_date, '%Y-%m-%d %H:%M')\n",
      "\n",
      "print('%s to %s' % (start_date, stop_date))"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bounding_box_type = \"box\" \n",
      "bounding_box = [[-87.4, 24.25],\n",
      "                [-74.7, 36.90]]  # SECOORA: NC, SC GA, FL\n",
      "\n",
      "box = []\n",
      "box.append(bounding_box[0][0])\n",
      "box.append(bounding_box[0][1])\n",
      "box.append(bounding_box[1][0])\n",
      "box.append(bounding_box[1][1])\n",
      "\n",
      "start, stop = dateRange(start_date, stop_date)\n",
      "bbox = fes.BBox(box)\n",
      "\n",
      "or_filt = fes.Or([fes.PropertyIsLike(propertyname='apiso:AnyText',\n",
      "                                     literal=('*%s*' % val),\n",
      "                                     escapeChar='\\\\',\n",
      "                                     wildCard='*',\n",
      "                                     singleChar='?') for val in name_list])\n",
      "\n",
      "val = 'Averages'\n",
      "not_filt = fes.Not([fes.PropertyIsLike(propertyname='apiso:AnyText',\n",
      "                                       literal=('*%s*' % val),\n",
      "                                       escapeChar='\\\\',\n",
      "                                       wildCard='*',\n",
      "                                       singleChar='?')])\n",
      "\n",
      "filter_list = [fes.And([bbox, start, stop, or_filt, not_filt])]"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CSW = {'NGDC Geoportal':\n",
      "       'http://www.ngdc.noaa.gov/geoportal/csw',\n",
      "       'USGS WHSC Geoportal':\n",
      "       'http://geoport.whoi.edu/geoportal/csw',\n",
      "       'NODC Geoportal: granule level':\n",
      "       'http://www.nodc.noaa.gov/geoportal/csw',\n",
      "       'NODC Geoportal: collection level':\n",
      "       'http://data.nodc.noaa.gov/geoportal/csw',\n",
      "       'NRCAN CUSTOM':\n",
      "       'http://geodiscover.cgdi.ca/wes/serviceManagerCSW/csw',\n",
      "       'USGS Woods Hole GI_CAT':\n",
      "       'http://geoport.whoi.edu/gi-cat/services/cswiso',\n",
      "       'USGS CIDA Geonetwork':\n",
      "       'http://cida.usgs.gov/gdp/geonetwork/srv/en/csw',\n",
      "       'USGS Coastal and Marine Program':\n",
      "       'http://cmgds.marine.usgs.gov/geonetwork/srv/en/csw',\n",
      "       'USGS Woods Hole Geoportal':\n",
      "       'http://geoport.whoi.edu/geoportal/csw',\n",
      "       'CKAN testing site for new Data.gov':\n",
      "       'http://geo.gov.ckan.org/csw',\n",
      "       'EPA':\n",
      "       'https://edg.epa.gov/metadata/csw',\n",
      "       'CWIC':\n",
      "       'http://cwic.csiss.gmu.edu/cwicv1/discovery'}\n",
      "\n",
      "endpoint = CSW['NGDC Geoportal']\n",
      "csw = CatalogueServiceWeb(endpoint, timeout=60)\n",
      "csw.getrecords2(constraints=filter_list, maxrecords=1000, esn='full')\n",
      "\n",
      "if False:\n",
      "    print(\"CSW version: %s\" % csw.version)\n",
      "    print(\"Number of datasets available: %s\" % len(csw.records.keys()))"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       0,
       29
      ]
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dap_urls = service_urls(csw.records, service='odp:url')\n",
      "sos_urls = service_urls(csw.records, service='sos:url')\n",
      "\n",
      "if False:\n",
      "    print(\"CSW:\")\n",
      "    for rec, item in csw.records.items():\n",
      "        print(item.title)\n",
      "    print(\"\\nDAP:\")\n",
      "    print(\"\\n\".join(dap_urls))\n",
      "    print(\"\\nSOS:\")\n",
      "    print(\"\\n\".join(sos_urls))"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collector = CoopsSos()\n",
      "\n",
      "collector.set_datum('MLLW')  # Should be NAVD\n",
      "collector.server.identification.title\n",
      "collector.start_time = jd_start\n",
      "collector.end_time = jd_stop\n",
      "collector.variables = [sos_name]\n",
      "\n",
      "ofrs = collector.server.offerings\n",
      "if False:\n",
      "    print(len(ofrs))"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iso_start = jd_start.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
      "iso_stop = jd_stop.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
      "box_str = ','.join(str(e) for e in box)\n",
      "\n",
      "print(\"Date: %s to %s\" % (iso_start, iso_stop))\n",
      "print(\"Lat/Lon Box: %s\" % box_str)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = ('http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS?'\n",
      "       'service=SOS&request=GetObservation&version=1.0.0&'\n",
      "       'observedProperty=%s&offering=urn:ioos:network:NOAA.NOS.CO-OPS:'\n",
      "       'WaterLevelActive&featureOfInterest=BBOX:%s&responseFormat='\n",
      "       'text/csv&eventTime=%s' % (sos_name, box_str, iso_start))\n",
      "\n",
      "observations = read_csv(url)\n",
      "if False:\n",
      "    print(url)"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Clean dataframe.\n",
      "columns = {'station_id': 'station',\n",
      "           'sensor_id': 'sensor',\n",
      "           'datum_id': 'datum',\n",
      "           'latitude (degree)': 'lat',\n",
      "           'longitude (degree)': 'lon',\n",
      "           'vertical_position (m)': 'height',\n",
      "           'water_surface_height_above_reference_datum (m)': 'ssh above datum'}\n",
      "\n",
      "observations.rename(columns=columns, inplace=True)\n",
      "\n",
      "observations['station'] = [sta.split(':')[-1] for sta in observations['station']]\n",
      "observations['sensor'] = [sta.split(':')[-1] for sta in observations['sensor']]\n",
      "observations['datum'] = [sta.split(':')[-1] for sta in observations['datum']]\n",
      "observations['name'] = [get_Coops_longName(sta) for sta in observations['station']]\n",
      "\n",
      "observations.set_index('station', inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "observations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = folium.Map(location=[np.mean(bounding_box, axis=0)[1],\n",
      "                         np.mean(bounding_box, axis=0)[0]],\n",
      "               zoom_start=5)\n",
      "\n",
      "# Create the map and add the bounding box line.\n",
      "m.line(get_coordinates(bounding_box, bounding_box_type),\n",
      "       line_color='#FF0000', line_weight=2)\n",
      "\n",
      "for station, row in observations.iterrows():\n",
      "    if row['datum'] == 'NADV':\n",
      "        popup_string = '<b>Station:</b><br>%s<br><b>Long Name:</b><br>%s' % (station, row['name'])\n",
      "        m.simple_marker(location=[row['lat'], row['lon']], popup=popup_string)\n",
      "    else:\n",
      "        popup_string = '<b>Not NAVD</b><br><b>Station:</b><br>%s<br><b>Long Name:</b><br>%s' % (station, row['name'])\n",
      "        m.circle_marker(location=[row['lat'], row['lon']], popup=popup_string,\n",
      "                        fill_color='#ff0000', radius=10000, line_color='#ff0000')\n",
      "if False:\n",
      "    for model, row in models.iterrows():\n",
      "        popup_string = '<b>Station:</b><br>%s<br><b>Long Name:</b><br>%s' % (station, row['name'])\n",
      "        m.simple_marker(location=[row['lat'], row['lon']], popup=popup_string)\n",
      "\n",
      "inline_map(m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generate a uniform 6-min time base for model/data comparison:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = dict()\n",
      "\n",
      "for sta in observations.index:\n",
      "    b = coops2df(collector, sta, sos_name)['water_surface_height_above_reference_datum (m)']\n",
      "    data.update({sta: b})\n",
      "    \n",
      "obs_data = DataFrame.from_dict(data).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Get model output from OPeNDAP URLS"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('\\n'.join(name_list))\n",
      "\n",
      "name_in_list = lambda cube: cube.standard_name in name_list\n",
      "constraint = iris.Constraint(cube_func=name_in_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use only data where the standard deviation of the time series exceeds 0.01 m\n",
      "# (1 cm) this eliminates flat line model time series that come from land\n",
      "# points that should have had missing values.\n",
      "min_var = 0.01\n",
      "\n",
      "# Use only data within 0.04 degrees (about 4 km).\n",
      "max_dist = 0.04"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for url in dap_urls:\n",
      "    try:\n",
      "        a = iris.load_cube(url, constraint)\n",
      "        # Convert to units of meters:\n",
      "        # a.convert_units('m')  # This isn't working for unstructured data.\n",
      "        mod_name = a.attributes['title']\n",
      "        r = a.shape\n",
      "        timevar = find_timevar(a)\n",
      "        lat = a.coord(axis='Y').points\n",
      "        lon = a.coord(axis='X').points\n",
      "        jd = timevar.units.num2date(timevar.points)\n",
      "        start = timevar.units.date2num(jd_start)\n",
      "        istart = timevar.nearest_neighbour_index(start)\n",
      "        stop = timevar.units.date2num(jd_stop)\n",
      "        istop = timevar.nearest_neighbour_index(stop)\n",
      "        print(mod_name, url)\n",
      "        if False:\n",
      "            # Only proceed if we have data in the range requested.\n",
      "            if istart != istop:\n",
      "                nsta = len(obs_lon)\n",
      "                if len(r) == 3:\n",
      "                    print('[Structured grid model]:', url)\n",
      "                    d = a[0, :, :].data\n",
      "                    # Find the closest non-land point from a structured grid model.\n",
      "                    if len(lon.shape) == 1:\n",
      "                        lon, lat = np.meshgrid(lon, lat)\n",
      "                    j, i, dd = find_ij(lon, lat, d, obs_lon, obs_lat)\n",
      "                    for n in range(nsta):\n",
      "                        # Only use if model cell is within 0.1 degree of requested\n",
      "                        # location.\n",
      "                        if dd[n] <= max_dist:\n",
      "                            arr = a[istart:istop, j[n], i[n]].data\n",
      "                            if arr.std() >= min_var:\n",
      "                                c = mod_df(arr, timevar, istart, istop,\n",
      "                                           mod_name, ts)\n",
      "                                name = obs_df[n].name\n",
      "                                obs_df[n] = concat([obs_df[n], c], axis=1)\n",
      "                                obs_df[n].name = name\n",
      "                elif len(r) == 2:\n",
      "                    print('[Unstructured grid model]:', url)\n",
      "                    # Find the closest point from an unstructured grid model.\n",
      "                    index, dd = nearxy(lon.flatten(), lat.flatten(),\n",
      "                                       obs_lon, obs_lat)\n",
      "                    for n in range(nsta):\n",
      "                        # Only use if model cell is within 0.1 degree of requested\n",
      "                        # location.\n",
      "                        if dd[n] <= max_dist:\n",
      "                            arr = a[istart:istop, index[n]].data\n",
      "                            if arr.std() >= min_var:\n",
      "                                c = mod_df(arr, timevar, istart, istop,\n",
      "                                           mod_name, ts)\n",
      "                                name = obs_df[n].name\n",
      "                                obs_df[n] = concat([obs_df[n], c], axis=1)\n",
      "                                obs_df[n].name = name\n",
      "                elif len(r) == 1:\n",
      "                    print('[Data]:', url)\n",
      "    except (ValueError, RuntimeError, CoordinateNotFoundError,\n",
      "            ConstraintMismatchError) as e:\n",
      "        warn(\"\\n%s\\n\" % e)\n",
      "        pass"
     ],
     "language": "python",
     "metadata": {
      "code_folding": [
       15,
       26,
       37
      ]
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for df in obs_df:\n",
      "    ax = df.plot(figsize=(14, 6), title=df.name, legend=False)\n",
      "    plt.setp(ax.lines[0], linewidth=4.0, color='0.7', zorder=1)\n",
      "    ax.legend()\n",
      "    ax.set_ylabel('m')"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plot again, but now remove the mean offset (relative to data) from all plots."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if True:\n",
      "    for df in obs_df:\n",
      "        amean = df[jd_start:jd_now].mean()\n",
      "        name = df.name\n",
      "        df = df - amean + amean.ix[0]\n",
      "        df.name = name\n",
      "        ax = df.plot(figsize=(14, 6), title=df.name, legend=False)\n",
      "        plt.setp(ax.lines[0], linewidth=4.0, color='0.7', zorder=1)\n",
      "        ax.legend()\n",
      "        ax.set_ylabel('m')\n",
      "        print(amean.ix[0] - amean)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}