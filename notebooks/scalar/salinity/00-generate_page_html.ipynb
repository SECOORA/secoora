{
 "metadata": {
  "kernelspec": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "display_name": "IOOS (Python 2)",
   "language": "python",
   "name": "ioos_python2"
  },
  "name": "",
  "signature": "sha256:082428680a1ea732ba6fe209c6354a42c8148e4b038c729e2ea0c9cfbf4a46f8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris\n",
      "import pyoos\n",
      "import owslib\n",
      "\n",
      "import time\n",
      "start_time = time.time()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "\n",
      "utilities_path = os.path.join(os.getcwd(), os.pardir, os.pardir)\n",
      "root = os.path.abspath(utilities_path)\n",
      "sys.path.append(root)\n",
      "\n",
      "from utilities import timeit\n",
      "\n",
      "style = '../../style.css'\n",
      "\n",
      "dow = {d: i for i, d in\n",
      "       enumerate('Mon,Tue,Wed,Thu,Fri,Sat,Sun'.split(','))}\n",
      "\n",
      "\n",
      "def next_dow(date, day):\n",
      "    while date.weekday() != day:\n",
      "        date += timedelta(days=1)\n",
      "    return date"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### SECOORA salinity notebook\n",
      "Based on IOOS system-test [notebook](http://nbviewer.ipython.org/github/Bobfrat/system-test/blob/temp_nb/Theme_1_Baseline/Scenario_1E_Salinity.ipynb)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pytz\n",
      "from datetime import datetime, timedelta\n",
      "\n",
      "from utilities import CF_names\n",
      "\n",
      "\n",
      "# Choose the date range.\n",
      "if False:\n",
      "    kw = dict(hour=12, minute=0, second=0, microsecond=0)\n",
      "    stop = next_dow(datetime.utcnow(), dow['Fri']).replace(**kw)\n",
      "else:\n",
      "    stop = datetime(2014, 10, 10, 12)\n",
      "\n",
      "stop = stop.replace(tzinfo=pytz.utc)\n",
      "start = stop - timedelta(days=7)\n",
      "\n",
      "# SECOORA region (NC, SC GA, FL).\n",
      "bbox = [-87.40, 24.25, -74.70, 36.70]\n",
      "\n",
      "# CF-names to look for (Sea Surface Salinity).\n",
      "name_list = CF_names['salinity']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "directory = '{:%Y-%m-%d}'.format(stop)\n",
      "\n",
      "if not os.path.exists(directory):\n",
      "    os.makedirs(directory)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import logging as log\n",
      "reload(log)\n",
      "\n",
      "fmt = '{:*^64}'.format\n",
      "log.captureWarnings(True)\n",
      "LOG_FILENAME = 'log'\n",
      "LOG_FILENAME = os.path.join(directory, LOG_FILENAME)\n",
      "log.basicConfig(filename=LOG_FILENAME,\n",
      "                filemode='w',\n",
      "                format='%(asctime)s %(levelname)s: %(message)s',\n",
      "                datefmt='%I:%M:%S',\n",
      "                level=log.INFO,\n",
      "                stream=None)\n",
      "\n",
      "log.info(fmt(' Run information '))\n",
      "log.info('Run date: {:%Y-%m-%d %H:%M:%S}'.format(datetime.utcnow()))\n",
      "log.info('Download start: {:%Y-%m-%d %H:%M:%S}'.format(start))\n",
      "log.info('Download stop: {:%Y-%m-%d %H:%M:%S}'.format(stop))\n",
      "log.info('Bounding box: {0:3.2f}, {1:3.2f},'\n",
      "         '{2:3.2f}, {3:3.2f}'.format(*bbox))\n",
      "log.info(fmt(' Software version '))\n",
      "log.info('Iris version: {}'.format(iris.__version__))\n",
      "log.info('owslib version: {}'.format(owslib.__version__))\n",
      "log.info('pyoos version: {}'.format(pyoos.__version__))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from owslib import fes\n",
      "from utilities import fes_date_filter\n",
      "\n",
      "kw = dict(wildCard='*',\n",
      "          escapeChar='\\\\',\n",
      "          singleChar='?',\n",
      "          propertyname='apiso:AnyText')\n",
      "\n",
      "or_filt = fes.Or([fes.PropertyIsLike(literal=('*%s*' % val), **kw)\n",
      "                  for val in name_list])\n",
      "\n",
      "# Exculde ROMS Averages and History files.\n",
      "not_filt = fes.Not([fes.PropertyIsLike(literal='*Averages*', **kw)])\n",
      "\n",
      "begin, end = fes_date_filter(start, stop)\n",
      "filter_list = [fes.And([fes.BBox(bbox), begin, end, or_filt, not_filt])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from owslib.csw import CatalogueServiceWeb\n",
      "\n",
      "endpoint = 'http://www.ngdc.noaa.gov/geoportal/csw'\n",
      "csw = CatalogueServiceWeb(endpoint, timeout=60)\n",
      "csw.getrecords2(constraints=filter_list, maxrecords=1000, esn='full')\n",
      "\n",
      "log.info(fmt(' Catalog information '))\n",
      "log.info(\"URL: {}\".format(endpoint))\n",
      "log.info(\"CSW version: {}\".format(csw.version))\n",
      "log.info(\"Number of datasets available: {}\".format(len(csw.records.keys())))"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utilities import service_urls\n",
      "\n",
      "dap_urls = service_urls(csw.records, service='odp:url')\n",
      "sos_urls = service_urls(csw.records, service='sos:url')\n",
      "\n",
      "log.info(fmt(' CSW URLs '))\n",
      "for rec, item in csw.records.items():\n",
      "    log.info('{}'.format(item.title))\n",
      "\n",
      "log.info(fmt(' DAP URLs '))\n",
      "for url in dap_urls:\n",
      "    log.info('{}.html'.format(url))\n",
      "\n",
      "log.info(fmt(' SOS URLs '))\n",
      "for url in sos_urls:\n",
      "    log.info('{}'.format(url))"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyoos.collectors.coops.coops_sos import CoopsSos\n",
      "\n",
      "collector = CoopsSos()\n",
      "sos_name = 'salinity'\n",
      "\n",
      "collector.end_time = stop\n",
      "collector.start_time = start\n",
      "collector.variables = [sos_name]\n",
      "\n",
      "ofrs = collector.server.offerings\n",
      "title = collector.server.identification.title\n",
      "log.info(fmt(' Collector offerings '))\n",
      "log.info('{}: {} offerings'.format(title, len(ofrs)))"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import read_csv\n",
      "from utilities import sos_request\n",
      "\n",
      "params = dict(observedProperty=sos_name,\n",
      "              eventTime=start.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
      "              featureOfInterest='BBOX:{0},{1},{2},{3}'.format(*bbox),\n",
      "              offering='urn:ioos:network:NOAA.NOS.CO-OPS:MetActive')\n",
      "\n",
      "uri = 'http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS'\n",
      "url = sos_request(uri, **params)\n",
      "observations = read_csv(url)\n",
      "\n",
      "log.info('SOS URL request: {}'.format(url))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Clean the dataframe (visualization purpose only)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utilities import get_coops_longname, to_html\n",
      "\n",
      "columns = {'sensor_id': 'sensor',\n",
      "           'station_id': 'station',\n",
      "           'latitude (degree)': 'lat',\n",
      "           'longitude (degree)': 'lon',\n",
      "           #?'salinity': 'salinity'}\n",
      "\n",
      "observations.rename(columns=columns, inplace=True)\n",
      "\n",
      "observations['sensor'] = [s.split(':')[-1] for s in observations['sensor']]\n",
      "observations['station'] = [s.split(':')[-1] for s in observations['station']]\n",
      "observations['name'] = [get_coops_longname(s) for s in observations['station']]\n",
      "\n",
      "observations.set_index('name', inplace=True)\n",
      "to_html(observations.head(), style)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Generate a uniform 6-min time base for model/data comparison"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris\n",
      "from pandas import DataFrame\n",
      "from owslib.ows import ExceptionReport\n",
      "from utilities import coops2df, save_timeseries\n",
      "\n",
      "iris.FUTURE.netcdf_promote = True\n",
      "\n",
      "log.info(fmt(' Observations (station data) '))\n",
      "fname = '{:%Y-%m-%d}-OBS_DATA.nc'.format(stop)\n",
      "fname = os.path.join(directory, fname)\n",
      "\n",
      "log.info(fmt(' Downloading to file {} '.format(fname)))\n",
      "data = dict()\n",
      "bad_station = []\n",
      "for station in observations.station:\n",
      "    try:\n",
      "        df = coops2df(collector, station)\n",
      "        #?col = 'salinity'\n",
      "        data.update({station: df[col]})\n",
      "    except ExceptionReport as e:\n",
      "        bad_station.append(station)\n",
      "        name = get_coops_longname(station)\n",
      "        log.warning(\"[{}] {}:\\n{}\".format(station, name, e))\n",
      "obs_data = DataFrame.from_dict(data)\n",
      "\n",
      "# Split good and bad stations.\n",
      "pattern = '|'.join(bad_station)\n",
      "if pattern:\n",
      "    mask = observations.station.str.contains(pattern)\n",
      "    bad_station = observations[mask]\n",
      "    bservations = observations[~mask]\n",
      "\n",
      "comment = \"Several stations from http://opendap.co-ops.nos.noaa.gov\"\n",
      "kw = dict(longitude=observations.lon,\n",
      "          latitude=observations.lat,\n",
      "          station_attr=dict(cf_role=\"timeseries_id\"),\n",
      "          cube_attr=dict(featureType='timeSeries',\n",
      "                         Conventions='CF-1.6',\n",
      "                         standard_name_vocabulary='CF-1.6',\n",
      "                         cdm_data_type=\"Station\",\n",
      "                         comment=comment,\n",
      "                         url=url))\n",
      "\n",
      "save_timeseries(obs_data, outfile=fname,\n",
      "                standard_name=sos_name, **kw)\n",
      "\n",
      "to_html(obs_data.head(), style)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Loop discovered models and save the nearest time-series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from iris.pandas import as_series\n",
      "from iris.exceptions import (CoordinateNotFoundError, ConstraintMismatchError,\n",
      "                             MergeError)\n",
      "\n",
      "from utilities import (standardize_fill_value, get_cube,\n",
      "                       get_model_name, make_tree, get_nearest_water,\n",
      "                       add_station, ensure_timeseries, get_surface,\n",
      "                       remove_ssh)\n",
      "\n",
      "# FIXME: Filtering out NECOFS  and estofs.\n",
      "dap_urls = [link for link in dap_urls\n",
      "            if 'NECOFS' not in link]  # Cartesian coords are not implemented.\n",
      "\n",
      "log.info(fmt(' Models (simulated data) '))\n",
      "for k, url in enumerate(dap_urls):\n",
      "    with timeit(log):\n",
      "        log.info('\\n[Reading url {}/{}]: {}'.format(k+1, len(dap_urls), url))\n",
      "        try:\n",
      "            cube = get_cube(url, name_list=name_list, bbox=bbox,\n",
      "                            time=(start, stop),\n",
      "                            units=iris.unit.Unit('g/kg'))\n",
      "            cube = get_surface(cube)  # FIXME: Surface data only!\n",
      "            if cube.ndim == 1:  # We Need a better way to identify model data.\n",
      "                log.warning('url {} is probably a timeSeries!'.format(url))\n",
      "                continue\n",
      "        except (RuntimeError, ValueError, MergeError,\n",
      "                ConstraintMismatchError, CoordinateNotFoundError) as e:\n",
      "            log.warning('Cannot get cube for: {}\\n{}'.format(url, e))\n",
      "            continue\n",
      "\n",
      "        mod_name, model_full_name = get_model_name(cube, url)\n",
      "\n",
      "        fname = '{:%Y-%m-%d}-{}.nc'.format(stop, mod_name)\n",
      "        fname = os.path.join(directory, fname)\n",
      "        log.info(fmt(' Downloading to file {} '.format(fname)))\n",
      "        try:  # Make tree.\n",
      "            tree, lon, lat = make_tree(cube)\n",
      "        except CoordinateNotFoundError as e:\n",
      "            log.warning('Cannot make KDTree for: {}'.format(mod_name))\n",
      "            continue\n",
      "        # Get model series at observed locations.\n",
      "        raw_series = dict()\n",
      "        for station, obs in observations.iterrows():\n",
      "            a = obs_data[obs['station']]\n",
      "            try:\n",
      "                kw = dict(k=10, max_dist=0.04, min_var=0.01)\n",
      "                args = cube, tree, obs.lon, obs.lat\n",
      "                series, dist, idx = get_nearest_water(*args, **kw)\n",
      "            # RuntimeError may occurs, but you should run it again!\n",
      "            except ValueError as e:\n",
      "                log.warning(e)\n",
      "                continue\n",
      "            if not series:\n",
      "                status = \"Found Land\"\n",
      "            else:\n",
      "                raw_series.update({obs['station']: series})\n",
      "                series = as_series(series)\n",
      "                status = \"Found Water\"\n",
      "\n",
      "            log.info('[{}] {}'.format(status, obs.name))\n",
      "\n",
      "        if raw_series:  # Save cube.\n",
      "            for station, cube in raw_series.items():\n",
      "                cube = standardize_fill_value(cube)\n",
      "                cube = add_station(cube, station)\n",
      "                cube = remove_ssh(cube)\n",
      "            try:\n",
      "                cube = iris.cube.CubeList(raw_series.values()).merge_cube()\n",
      "            except MergeError as e:\n",
      "                log.warning(e)\n",
      "\n",
      "            ensure_timeseries(cube)\n",
      "            iris.save(cube, fname)\n",
      "            del cube\n",
      "\n",
      "    log.info('[{}]: {}'.format(mod_name, url))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Load saved files and interpolate to the observations time interval"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from glob import glob\n",
      "from operator import itemgetter\n",
      "\n",
      "from pandas import Panel\n",
      "from utilities import nc2df\n",
      "\n",
      "fname = '{}-OBS_DATA.nc'.format(directory)\n",
      "fname = os.path.join(directory, fname)\n",
      "OBS_DATA = nc2df(fname)\n",
      "index = OBS_DATA.index\n",
      "\n",
      "dfs = dict(OBS_DATA=OBS_DATA)\n",
      "for fname in glob(os.path.join(directory, \"*.nc\")):\n",
      "    if 'OBS_DATA' in fname:\n",
      "        continue\n",
      "    else:\n",
      "        model = fname.split('.')[0].split('-')[-1]\n",
      "        df = nc2df(fname)\n",
      "        kw = dict(method='time', limit=30)\n",
      "        df = df.reindex(index).interpolate(**kw).ix[index]\n",
      "        dfs.update({model: df})\n",
      "\n",
      "dfs = Panel.fromDict(dfs).swapaxes(0, 2)\n",
      "\n",
      "# Clusters.\n",
      "big_list = []\n",
      "for fname in glob(os.path.join(directory, \"*.nc\")):\n",
      "    if 'OBS_DATA' in fname:\n",
      "        continue\n",
      "    nc = iris.load_cube(fname)\n",
      "    model = fname.split('-')[-1].split('.')[0]\n",
      "    lons = nc.coord(axis='X').points\n",
      "    lats = nc.coord(axis='Y').points\n",
      "    stations = nc.coord('station name').points\n",
      "    models = [model]*lons.size\n",
      "    lista = zip(models, lons.tolist(), lats.tolist(), stations.tolist())\n",
      "    big_list.extend(lista)\n",
      "\n",
      "big_list.sort(key=itemgetter(3))\n",
      "df = DataFrame(big_list, columns=['name', 'lon', 'lat', 'station'])\n",
      "df.set_index('station', drop=True, inplace=True)\n",
      "groups = df.groupby(df.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import vincent\n",
      "from utilities import inline_map, make_map\n",
      "\n",
      "salinity = make_map(bbox, line=True, states=False)\n",
      "\n",
      "# Clusters.\n",
      "for station, info in groups:\n",
      "    station = get_coops_longname(station)\n",
      "    for lat, lon, name in zip(info.lat, info.lon, info.name):\n",
      "        location = lat, lon\n",
      "        popup = '<b>{}</b>\\n{}'.format(station, name)\n",
      "        salinity.simple_marker(location=location, popup=popup,\n",
      "                                  clustered_marker=True)\n",
      "\n",
      "# Model and observations.\n",
      "for station in dfs:\n",
      "    sta_name = get_coops_longname(station)\n",
      "    df = dfs[station].dropna(axis=1, how='all')\n",
      "    # FIXME: This is bad!  But I cannot represent NaN with Vega!\n",
      "    df.fillna(value='null', inplace=True)\n",
      "    vis = vincent.Line(df, width=500, height=150)\n",
      "    vis.axis_titles(x='Time', y='Sea Surface Salinty (g/kg)')\n",
      "    vis.legend(title=sta_name)\n",
      "    vis.name = sta_name\n",
      "    vis.scales[0].zero = False\n",
      "    vis.scales[1].zero = False\n",
      "    json = 'station_{}.json'.format(station)\n",
      "    vis.to_json(os.path.join(directory, json))\n",
      "    obs = observations[observations['station'] == station].squeeze()\n",
      "    popup = (vis, json)\n",
      "    if (df.columns == 'OBS_DATA').all():\n",
      "        kw = dict(popup=popup, marker_color=\"blue\", marker_icon=\"ok\")\n",
      "    else:\n",
      "        if 'SABGOM' in df.columns:\n",
      "            kw = dict(popup=popup, marker_color=\"green\", marker_icon=\"ok-sign\")\n",
      "        else:\n",
      "            kw = dict(popup=popup, marker_color=\"green\", marker_icon=\"ok\")\n",
      "    salinity.simple_marker(location=[obs['lat'], obs['lon']], **kw)\n",
      "\n",
      "# Bad stations.\n",
      "if isinstance(bad_station, DataFrame):\n",
      "    for station, obs in bad_station.iterrows():\n",
      "        popup = '<b>Station:</b> {}'\n",
      "        popup = popup.format(station)\n",
      "        kw = dict(popup=popup, marker_color=\"red\", marker_icon=\"question-sign\")\n",
      "        salinity.simple_marker(location=[obs['lat'], obs['lon']], **kw)\n",
      "\n",
      "salinity.create_map(path=os.path.join(directory, 'salinity.html'))\n",
      "inline_map(os.path.join(directory, 'salinity.html'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elapsed = time.time() - start_time\n",
      "log.info(elapsed)\n",
      "log.info('EOF')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}