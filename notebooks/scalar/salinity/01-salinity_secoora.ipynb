{
 "metadata": {
  "kernelspec": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "display_name": "IOOS (Python 2)",
   "language": "python",
   "name": "ioos_python2"
  },
  "name": "",
  "signature": "sha256:3550030e98e101505f27267c97bc1b1eb5128c4c800418ca95f339e0ca8b5400"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris\n",
      "import pyoos\n",
      "import owslib\n",
      "\n",
      "import time\n",
      "start_time = time.time()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "\n",
      "utilities_path = os.path.join(os.getcwd(), os.pardir, os.pardir)\n",
      "root = os.path.abspath(utilities_path)\n",
      "sys.path.append(root)\n",
      "\n",
      "style = '../../style.css'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### SECOORA salinity notebook\n",
      "Based on IOOS system-test [notebook](http://nbviewer.ipython.org/github/Bobfrat/system-test/blob/temp_nb/Theme_1_Baseline/Scenario_1E_Salinity.ipynb)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pytz\n",
      "from datetime import datetime, timedelta\n",
      "\n",
      "\n",
      "# Choose the date range.\n",
      "# stop = datetime(2014, 7, 7, 12)  # FIXME: Hangs while trying to download data from FVCOM.\n",
      "stop = datetime(2014, 10, 10, 12)\n",
      "stop = stop.replace(tzinfo=pytz.utc)\n",
      "start = stop - timedelta(days=7)\n",
      "\n",
      "# SECOORA region (NC, SC GA, FL).\n",
      "bbox = [-87.40, 24.25, -74.70, 36.70]\n",
      "\n",
      "# CF-names to look for (Sea Surface Salinity).\n",
      "name_list = ['sea_water_salinity',\n",
      "             'sea_surface_salinity',\n",
      "             'sea_water_absolute_salinity',\n",
      "             'sea_water_practical_salinity']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fmt = '{:*^64}'.format\n",
      "print('Run date: {:%Y-%m-%d %H:%M:%S}'.format(datetime.utcnow()))\n",
      "print('Download start: {:%Y-%m-%d %H:%M:%S}'.format(start))\n",
      "print('Download stop: {:%Y-%m-%d %H:%M:%S}'.format(stop))\n",
      "print('Bounding box: {0:3.2f}, {1:3.2f},'\n",
      "      '{2:3.2f}, {3:3.2f}'.format(*bbox))\n",
      "print(fmt(' Software version '))\n",
      "print('Iris version: {}'.format(iris.__version__))\n",
      "print('owslib version: {}'.format(owslib.__version__))\n",
      "print('pyoos version: {}'.format(pyoos.__version__))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from owslib import fes\n",
      "from utilities import fes_date_filter\n",
      "\n",
      "kw = dict(wildCard='*',\n",
      "          escapeChar='\\\\',\n",
      "          singleChar='?',\n",
      "          propertyname='apiso:AnyText')\n",
      "\n",
      "or_filt = fes.Or([fes.PropertyIsLike(literal=('*%s*' % val), **kw)\n",
      "                  for val in name_list])\n",
      "\n",
      "# Exculde ROMS Averages and History files.\n",
      "not_filt = fes.Not([fes.PropertyIsLike(literal='*Averages*', **kw)])\n",
      "\n",
      "begin, end = fes_date_filter(start, stop)\n",
      "filter_list = [fes.And([fes.BBox(bbox), begin, end, or_filt, not_filt])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from owslib.csw import CatalogueServiceWeb\n",
      "\n",
      "endpoint = 'http://www.ngdc.noaa.gov/geoportal/csw'\n",
      "csw = CatalogueServiceWeb(endpoint, timeout=60)\n",
      "csw.getrecords2(constraints=filter_list, maxrecords=1000, esn='full')\n",
      "\n",
      "print(fmt(' Catalog information '))\n",
      "print(\"URL: {}\".format(endpoint))\n",
      "print(\"CSW version: {}\".format(csw.version))\n",
      "print(\"Number of datasets available: {}\".format(len(csw.records.keys())))"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utilities import service_urls\n",
      "\n",
      "dap_urls = service_urls(csw.records, service='odp:url')\n",
      "sos_urls = service_urls(csw.records, service='sos:url')\n",
      "\n",
      "print(fmt(' CSW URLs '))\n",
      "for rec, item in csw.records.items():\n",
      "    print('{}'.format(item.title))\n",
      "\n",
      "print(fmt(' DAP URLs '))\n",
      "for url in dap_urls:\n",
      "    print('{}.html'.format(url))\n",
      "\n",
      "print(fmt(' SOS URLs '))\n",
      "for url in sos_urls:\n",
      "    print('{}'.format(url))"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyoos.collectors.coops.coops_sos import CoopsSos\n",
      "\n",
      "collector = CoopsSos()\n",
      "sos_name = 'salinity'\n",
      "\n",
      "collector.end_time = stop\n",
      "collector.start_time = start\n",
      "collector.variables = [sos_name]\n",
      "\n",
      "ofrs = collector.server.offerings\n",
      "title = collector.server.identification.title\n",
      "print(fmt(' Collector offerings '))\n",
      "print('{}: {} offerings'.format(title, len(ofrs)))"
     ],
     "language": "python",
     "metadata": {
      "code_folding": []
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import read_csv\n",
      "from utilities import sos_request\n",
      "\n",
      "params = dict(observedProperty=sos_name,\n",
      "              eventTime=start.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
      "              featureOfInterest='BBOX:{0},{1},{2},{3}'.format(*bbox),\n",
      "              offering='urn:ioos:network:NOAA.NOS.CO-OPS:MetActive')\n",
      "\n",
      "uri = 'http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS'\n",
      "url = sos_request(uri, **params)\n",
      "observations = read_csv(url)\n",
      "\n",
      "print('SOS URL request: {}'.format(url))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Clean the dataframe (visualization purpose only)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utilities import get_coops_longname, to_html\n",
      "\n",
      "columns = {'sensor_id': 'sensor',\n",
      "           'station_id': 'station',\n",
      "           'latitude (degree)': 'lat',\n",
      "           'longitude (degree)': 'lon',\n",
      "           #?'salinity': 'salinity'}\n",
      "\n",
      "observations.rename(columns=columns, inplace=True)\n",
      "\n",
      "observations['sensor'] = [s.split(':')[-1] for s in observations['sensor']]\n",
      "observations['station'] = [s.split(':')[-1] for s in observations['station']]\n",
      "observations['name'] = [get_coops_longname(s) for s in observations['station']]\n",
      "\n",
      "observations.set_index('name', inplace=True)\n",
      "to_html(observations.head(), style)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Generate a uniform 6-min time base for model/data comparison"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris\n",
      "from pandas import DataFrame\n",
      "from owslib.ows import ExceptionReport\n",
      "from utilities import coops2df, save_timeseries\n",
      "\n",
      "iris.FUTURE.netcdf_promote = True\n",
      "fname = '{:%Y-%m-%d}-OBS_DATA.nc'.format(stop)\n",
      "print('Downloading observation to file {}.'.format(fname))\n",
      "\n",
      "data = dict()\n",
      "bad_station = []\n",
      "for station in observations.station:\n",
      "    try:\n",
      "        df = coops2df(collector, station)\n",
      "        #?col = 'salinity'\n",
      "        data.update({station: df[col]})\n",
      "    except ExceptionReport as e:\n",
      "        bad_station.append(station)\n",
      "        name = get_coops_longname(station)\n",
      "        print(\"[{}] {}:\\n{}\".format(station, name, e))\n",
      "obs_data = DataFrame.from_dict(data)\n",
      "\n",
      "# Split good and bad stations.\n",
      "pattern = '|'.join(bad_station)\n",
      "if pattern:\n",
      "    mask = observations.station.str.contains(pattern)\n",
      "    bad_station = observations[mask]\n",
      "    bservations = observations[~mask]\n",
      "\n",
      "comment = \"Several stations from http://opendap.co-ops.nos.noaa.gov\"\n",
      "kw = dict(longitude=observations.lon,\n",
      "          latitude=observations.lat,\n",
      "          station_attr=dict(cf_role=\"timeseries_id\"),\n",
      "          cube_attr=dict(featureType='timeSeries',\n",
      "                         Conventions='CF-1.6',\n",
      "                         standard_name_vocabulary='CF-1.6',\n",
      "                         cdm_data_type=\"Station\",\n",
      "                         comment=comment,\n",
      "                         url=url))\n",
      "\n",
      "save_timeseries(obs_data, outfile=fname,\n",
      "                standard_name=sos_name, **kw)\n",
      "\n",
      "to_html(obs_data.head(), style)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Loop discovered models and save the nearest time-series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from iris.pandas import as_series\n",
      "from iris.exceptions import (CoordinateNotFoundError, ConstraintMismatchError,\n",
      "                             MergeError)\n",
      "\n",
      "from utilities import (standardize_fill_value, plt_grid, get_cube,\n",
      "                       get_model_name, make_tree, get_nearest_water,\n",
      "                       add_station, ensure_timeseries, get_surface,\n",
      "                       remove_ssh)\n",
      "\n",
      "# FIXME: Filtering out NECOFS  and estofs.\n",
      "dap_urls = [link for link in dap_urls\n",
      "            if 'NECOFS' not in link]  # Cartesian coords are not implemented.\n",
      "\n",
      "print(fmt(' Models (simulated data) '))\n",
      "for k, url in enumerate(dap_urls):\n",
      "    print('\\n[Reading url {}/{}]: {}'.format(k+1, len(dap_urls), url))\n",
      "    try:\n",
      "        cube = get_cube(url, name_list=name_list, bbox=bbox,\n",
      "                        time=(start, stop),\n",
      "                        units=iris.unit.Unit('g/kg'))\n",
      "        print(cube.units)  # NOTE: Check this!\n",
      "        cube = get_surface(cube)  # FIXME: Surface data only!\n",
      "        if cube.ndim == 1:  # We Need a better way to identify model data.\n",
      "            print('url {} is probably a timeSeries!'.format(url))\n",
      "            continue\n",
      "    except (RuntimeError, ValueError, MergeError,\n",
      "            ConstraintMismatchError, CoordinateNotFoundError) as e:\n",
      "        print('Cannot get cube for: {}\\n{}'.format(url, e))\n",
      "        continue\n",
      "\n",
      "    mod_name, model_full_name = get_model_name(cube, url)\n",
      "\n",
      "    fname = '{:%Y-%m-%d}-{}.nc'.format(stop, mod_name)\n",
      "    print(fmt(' Downloading to file {} '.format(fname)))\n",
      "    try:  # Make tree.\n",
      "        tree, lon, lat = make_tree(cube)\n",
      "        fig, ax = plt_grid(lon, lat)\n",
      "    except CoordinateNotFoundError as e:\n",
      "        print('Cannot make KDTree for: {}'.format(mod_name))\n",
      "        continue\n",
      "    # Get model series at observed locations.\n",
      "    raw_series = dict()\n",
      "    for station, obs in observations.iterrows():\n",
      "        a = obs_data[obs['station']]\n",
      "        try:\n",
      "            kw = dict(k=10, max_dist=0.04, min_var=0.01)\n",
      "            args = cube, tree, obs.lon, obs.lat\n",
      "            series, dist, idx = get_nearest_water(*args, **kw)\n",
      "        # RuntimeError may occurs, but you should run it again!\n",
      "        except ValueError as e:\n",
      "            print(e)\n",
      "            continue\n",
      "        if not series:\n",
      "            status = \"Found Land\"\n",
      "        else:\n",
      "            raw_series.update({obs['station']: series})\n",
      "            series = as_series(series)\n",
      "            status = \"Found Water\"\n",
      "            ax.plot(lon[idx], lat[idx], 'g.')\n",
      "\n",
      "        print('[{}] {}'.format(status, obs.name))\n",
      "\n",
      "    if raw_series:  # Save cube.\n",
      "        for station, cube in raw_series.items():\n",
      "            cube = standardize_fill_value(cube)\n",
      "            cube = add_station(cube, station)\n",
      "            cube = remove_ssh(cube)\n",
      "        try:\n",
      "            cube = iris.cube.CubeList(raw_series.values()).merge_cube()\n",
      "        except MergeError as e:\n",
      "            print(e)\n",
      "\n",
      "        ensure_timeseries(cube)\n",
      "        iris.save(cube, fname)\n",
      "        del cube\n",
      "\n",
      "    size = len(raw_series)\n",
      "    ax.set_title('{}: Points found {}'.format(mod_name, size))\n",
      "    ax.plot(observations.lon, observations.lat, 'ro',\n",
      "            zorder=1, label='Observation', alpha=0.25)\n",
      "    ax.set_extent([bbox[0], bbox[2], bbox[1], bbox[3]])\n",
      "\n",
      "    print('[{}]: {}'.format(mod_name, url))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Load saved files and interpolate to the observations time interval"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from glob import glob\n",
      "from operator import itemgetter\n",
      "\n",
      "from pandas import Panel\n",
      "from utilities import nc2df\n",
      "\n",
      "fname = '{:%Y-%m-%d}-OBS_DATA.nc'.format(stop)\n",
      "\n",
      "OBS_DATA = nc2df(fname)\n",
      "index = OBS_DATA.index\n",
      "\n",
      "dfs = dict(OBS_DATA=OBS_DATA)\n",
      "for fname in glob(\"*.nc\"):\n",
      "    if 'OBS_DATA' in fname:\n",
      "        continue\n",
      "    else:\n",
      "        model = fname.split('.')[0].split('-')[-1]\n",
      "        df = nc2df(fname)\n",
      "        kw = dict(method='time', limit=30)\n",
      "        df = df.reindex(index).interpolate(**kw).ix[index]\n",
      "        dfs.update({model: df})\n",
      "\n",
      "dfs = Panel.fromDict(dfs).swapaxes(0, 2)\n",
      "\n",
      "# Clusters.\n",
      "big_list = []\n",
      "for fname in glob(\"*.nc\"):\n",
      "    if 'OBS_DATA' in fname:\n",
      "        continue\n",
      "    nc = iris.load_cube(fname)\n",
      "    model = fname.split('-')[-1].split('.')[0]\n",
      "    lons = nc.coord(axis='X').points\n",
      "    lats = nc.coord(axis='Y').points\n",
      "    stations = nc.coord('station name').points\n",
      "    models = [model]*lons.size\n",
      "    lista = zip(models, lons.tolist(), lats.tolist(), stations.tolist())\n",
      "    big_list.extend(lista)\n",
      "\n",
      "big_list.sort(key=itemgetter(3))\n",
      "df = DataFrame(big_list, columns=['name', 'lon', 'lat', 'station'])\n",
      "df.set_index('station', drop=True, inplace=True)\n",
      "groups = df.groupby(df.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import vincent\n",
      "from utilities import inline_map, make_map\n",
      "\n",
      "salinity = make_map(bbox, line=True, states=False)\n",
      "\n",
      "# Clusters.\n",
      "for station, info in groups:\n",
      "    station = get_coops_longname(station)\n",
      "    for lat, lon, name in zip(info.lat, info.lon, info.name):\n",
      "        location = lat, lon\n",
      "        popup = '<b>{}</b>\\n{}'.format(station, name)\n",
      "        salinity.simple_marker(location=location, popup=popup,\n",
      "                               clustered_marker=True)\n",
      "\n",
      "# Model and observations.\n",
      "for station in dfs:\n",
      "    sta_name = get_coops_longname(station)\n",
      "    df = dfs[station].dropna(axis=1, how='all')\n",
      "    # FIXME: This is bad!  But I cannot represent NaN with Vega!\n",
      "    df.fillna(value='null', inplace=True)\n",
      "    vis = vincent.Line(df, width=500, height=150)\n",
      "    vis.axis_titles(x='Time', y='Sea Surface Salinity (g/kg)')\n",
      "    vis.legend(title=sta_name)\n",
      "    vis.name = sta_name\n",
      "    vis.scales[0].zero = False\n",
      "    vis.scales[1].zero = False\n",
      "    json = 'station_{}.json'.format(station)\n",
      "    vis.to_json(json)\n",
      "    obs = observations[observations['station'] == station].squeeze()\n",
      "    popup = (vis, json)\n",
      "    if (df.columns == 'OBS_DATA').all():\n",
      "        kw = dict(popup=popup, marker_color=\"blue\", marker_icon=\"ok\")\n",
      "    else:\n",
      "        if 'SABGOM' in df.columns:\n",
      "            kw = dict(popup=popup, marker_color=\"green\", marker_icon=\"ok-sign\")\n",
      "        else:\n",
      "            kw = dict(popup=popup, marker_color=\"green\", marker_icon=\"ok\")\n",
      "    salinity.simple_marker(location=[obs['lat'], obs['lon']], **kw)\n",
      "\n",
      "# Bad stations.\n",
      "if isinstance(bad_station, DataFrame):\n",
      "    for station, obs in bad_station.iterrows():\n",
      "        popup = '<b>Station:</b> {}'\n",
      "        popup = popup.format(station)\n",
      "        kw = dict(popup=popup, marker_color=\"red\", marker_icon=\"question-sign\")\n",
      "        salinity.simple_marker(location=[obs['lat'], obs['lon']], **kw)\n",
      "\n",
      "salinity.create_map(path='salinity.html')\n",
      "inline_map('salinity.html')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elapsed = time.time() - start_time\n",
      "\n",
      "print(str(timedelta(seconds=elapsed)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}