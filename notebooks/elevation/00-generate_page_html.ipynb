{
 "metadata": {
  "name": "",
  "signature": "sha256:99e72658ecf918fe2c07633e4cdc97a9acaf29e1dc691e59c8f4aec0957b0690"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### This notebook generates the weekly map and table HTMLs for the SECOORA web-page."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris\n",
      "import pyoos\n",
      "import owslib\n",
      "\n",
      "import time\n",
      "start_time = time.time()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "\n",
      "utilities_path = os.path.join(os.getcwd(), os.pardir)\n",
      "root = os.path.abspath(utilities_path)\n",
      "sys.path.append(root)\n",
      "\n",
      "style = '../style.css'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### SECOORA inundation notebook\n",
      "Based on IOOS system-test [notebook](http://nbviewer.ipython.org/github/ioos/system-test/blob/master/Theme_2_Extreme_Events/Scenario_2A/ModelDataCompare_Inundation/Water_Level_Signell.ipynb)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pytz\n",
      "from datetime import datetime, timedelta\n",
      "\n",
      "from utilities import CF_names\n",
      "\n",
      "\n",
      "# Choose the date range.\n",
      "stop = datetime(2014, 11, 28, 12)\n",
      "\n",
      "stop = stop.replace(tzinfo=pytz.utc)\n",
      "start = stop - timedelta(days=7)\n",
      "\n",
      "# SECOORA region (NC, SC GA, FL).\n",
      "bbox = [-87.40, 24.25, -74.70, 36.70]\n",
      "\n",
      "# CF-names to look for (Sea Surface Height).\n",
      "name_list = CF_names['water level']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "directory = '{:%Y-%m-%d}'.format(stop)\n",
      "\n",
      "if not os.path.exists(directory):\n",
      "    os.makedirs(directory)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import logging as log\n",
      "reload(log)\n",
      "\n",
      "fmt = '{:*^64}'.format\n",
      "log.captureWarnings(True)\n",
      "LOG_FILENAME = 'log'\n",
      "LOG_FILENAME = os.path.join(directory, LOG_FILENAME)\n",
      "log.basicConfig(filename=LOG_FILENAME,\n",
      "                filemode='w',\n",
      "                format='%(asctime)s %(levelname)s: %(message)s',\n",
      "                datefmt='%I:%M:%S',\n",
      "                level=log.INFO,\n",
      "                stream=None)\n",
      "\n",
      "log.info(fmt(' Run information '))\n",
      "log.info('Run date: {:%Y-%m-%d %H:%M:%S}'.format(datetime.utcnow()))\n",
      "log.info('Download start: {:%Y-%m-%d %H:%M:%S}'.format(start))\n",
      "log.info('Download stop: {:%Y-%m-%d %H:%M:%S}'.format(stop))\n",
      "log.info('Bounding box: {0:3.2f}, {1:3.2f},'\n",
      "         '{2:3.2f}, {3:3.2f}'.format(*bbox))\n",
      "log.info(fmt(' Software version '))\n",
      "log.info('Iris version: {}'.format(iris.__version__))\n",
      "log.info('owslib version: {}'.format(owslib.__version__))\n",
      "log.info('pyoos version: {}'.format(pyoos.__version__))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from owslib import fes\n",
      "from utilities import fes_date_filter\n",
      "\n",
      "kw = dict(wildCard='*',\n",
      "          escapeChar='\\\\',\n",
      "          singleChar='?',\n",
      "          propertyname='apiso:AnyText')\n",
      "\n",
      "or_filt = fes.Or([fes.PropertyIsLike(literal=('*%s*' % val), **kw)\n",
      "                  for val in name_list])\n",
      "\n",
      "not_filt = fes.Not([fes.PropertyIsLike(literal='*Averages*', **kw)])\n",
      "\n",
      "begin, end = fes_date_filter(start, stop)\n",
      "filter_list = [fes.And([fes.BBox(bbox), begin, end, or_filt, not_filt])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from owslib.csw import CatalogueServiceWeb\n",
      "\n",
      "endpoint = 'http://www.ngdc.noaa.gov/geoportal/csw'\n",
      "csw = CatalogueServiceWeb(endpoint, timeout=60)\n",
      "csw.getrecords2(constraints=filter_list, maxrecords=1000, esn='full')\n",
      "\n",
      "log.info(fmt(' Catalog information '))\n",
      "log.info(\"URL: {}\".format(endpoint))\n",
      "log.info(\"CSW version: {}\".format(csw.version))\n",
      "log.info(\"Number of datasets available: {}\".format(len(csw.records.keys())))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utilities import service_urls\n",
      "\n",
      "dap_urls = service_urls(csw.records, service='odp:url')\n",
      "sos_urls = service_urls(csw.records, service='sos:url')\n",
      "\n",
      "log.info(fmt(' CSW URLs '))\n",
      "for rec, item in csw.records.items():\n",
      "    log.info('{}'.format(item.title))\n",
      "\n",
      "log.info(fmt(' DAP URLs '))\n",
      "for url in dap_urls:\n",
      "    log.info('{}.html'.format(url))\n",
      "\n",
      "log.info(fmt(' SOS URLs '))\n",
      "for url in sos_urls:\n",
      "    log.info('{}'.format(url))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Force SABGOM and USEAST into the URL list.\n",
      "from utilities import titles\n",
      "if titles['SABGOM'] not in dap_urls:\n",
      "    log.warning('SABGOM not in the catalog')\n",
      "    dap_urls.append(titles['SABGOM'])\n",
      "\n",
      "if titles['USEAST'] not in dap_urls:\n",
      "    log.warning('USEAST not in the catalog')\n",
      "    dap_urls.append(titles['USEAST'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyoos.collectors.coops.coops_sos import CoopsSos\n",
      "\n",
      "collector = CoopsSos()\n",
      "sos_name = 'water_surface_height_above_reference_datum'\n",
      "\n",
      "datum = 'NAVD'\n",
      "collector.set_datum(datum)\n",
      "collector.end_time = stop\n",
      "collector.start_time = start\n",
      "collector.variables = [sos_name]\n",
      "\n",
      "ofrs = collector.server.offerings\n",
      "title = collector.server.identification.title\n",
      "log.info(fmt(' Collector offerings '))\n",
      "log.info('{}: {} offerings'.format(title, len(ofrs)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import read_csv\n",
      "from utilities import sos_request\n",
      "\n",
      "params = dict(observedProperty=sos_name,\n",
      "              eventTime=start.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
      "              featureOfInterest='BBOX:{0},{1},{2},{3}'.format(*bbox),\n",
      "              offering='urn:ioos:network:NOAA.NOS.CO-OPS:WaterLevelActive')\n",
      "\n",
      "uri = 'http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS'\n",
      "url = sos_request(uri, **params)\n",
      "observations = read_csv(url)\n",
      "\n",
      "log.info('SOS URL request: {}'.format(url))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Clean the dataframe (visualization purpose only)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utilities import get_coops_longname, to_html\n",
      "\n",
      "columns = {'datum_id': 'datum',\n",
      "           'sensor_id': 'sensor',\n",
      "           'station_id': 'station',\n",
      "           'latitude (degree)': 'lat',\n",
      "           'longitude (degree)': 'lon',\n",
      "           'vertical_position (m)': 'height',\n",
      "           'water_surface_height_above_reference_datum (m)': 'ssh above datum'}\n",
      "\n",
      "observations.rename(columns=columns, inplace=True)\n",
      "\n",
      "observations['datum'] = [s.split(':')[-1] for s in observations['datum']]\n",
      "observations['sensor'] = [s.split(':')[-1] for s in observations['sensor']]\n",
      "observations['station'] = [s.split(':')[-1] for s in observations['station']]\n",
      "observations['name'] = [get_coops_longname(s) for s in observations['station']]\n",
      "\n",
      "observations.set_index('name', inplace=True)\n",
      "to_html(observations.head(), style)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Generate a uniform 6-min time base for model/data comparison"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris\n",
      "from pandas import DataFrame\n",
      "from owslib.ows import ExceptionReport\n",
      "from utilities import coops2df, save_timeseries\n",
      "\n",
      "iris.FUTURE.netcdf_promote = True\n",
      "\n",
      "log.info(fmt(' Observations (station data) '))\n",
      "fname = '{:%Y-%m-%d}-OBS_DATA.nc'.format(stop)\n",
      "fname = os.path.join(directory, fname)\n",
      "\n",
      "log.info(fmt(' Downloading to file {} '.format(fname)))\n",
      "data = dict()\n",
      "bad_datum = []\n",
      "for station in observations.station:\n",
      "    try:\n",
      "        df = coops2df(collector, station)\n",
      "        col = 'water_surface_height_above_reference_datum (m)'\n",
      "        data.update({station: df[col]})\n",
      "    except ExceptionReport as e:\n",
      "        bad_datum.append(station)\n",
      "        name = get_coops_longname(station)\n",
      "        log.warning(\"[{}] {}:\\n{}\".format(station, name, e))\n",
      "obs_data = DataFrame.from_dict(data)\n",
      "\n",
      "# Split good and bad vertical datum stations.\n",
      "pattern = '|'.join(bad_datum)\n",
      "if pattern:\n",
      "    non_navd = observations.station.str.contains(pattern)\n",
      "    bad_datum = observations[non_navd]\n",
      "    observations = observations[~non_navd]\n",
      "\n",
      "comment = \"Several stations from http://opendap.co-ops.nos.noaa.gov\"\n",
      "kw = dict(longitude=observations.lon,\n",
      "          latitude=observations.lat,\n",
      "          station_attr=dict(cf_role=\"timeseries_id\"),\n",
      "          cube_attr=dict(featureType='timeSeries',\n",
      "                         Conventions='CF-1.6',\n",
      "                         standard_name_vocabulary='CF-1.6',\n",
      "                         cdm_data_type=\"Station\",\n",
      "                         comment=comment,\n",
      "                         datum=datum,\n",
      "                         url=url))\n",
      "\n",
      "save_timeseries(obs_data, outfile=fname,\n",
      "                standard_name=sos_name, **kw)\n",
      "\n",
      "to_html(obs_data.head(), style)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Loop discovered models and save the nearest time-series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from iris.exceptions import (CoordinateNotFoundError, ConstraintMismatchError,\n",
      "                             MergeError)\n",
      "\n",
      "from utilities import TimeoutException, time_limit, get_cube, get_model_name\n",
      "\n",
      "# FIXME: Filtering bad URLs.\n",
      "dap_urls = [link for link in dap_urls\n",
      "            if 'NECOFS' not in link]  # Cartesian coords are not implemented.\n",
      "\n",
      "log.info(fmt(' Models (simulated data) '))\n",
      "cubes = dict()\n",
      "for k, url in enumerate(dap_urls):\n",
      "    log.info('\\n[Reading url {}/{}]: {}'.format(k+1, len(dap_urls), url))\n",
      "    try:\n",
      "        with time_limit(60*5):\n",
      "            cube = get_cube(url, name_list=name_list,\n",
      "                            bbox=bbox, time=(start, stop),\n",
      "                            units=iris.unit.Unit('meters'))\n",
      "        # TODO: Need a better way to identify model data and observed data.\n",
      "        if cube.ndim > 1:\n",
      "            mod_name, model_full_name = get_model_name(cube, url)\n",
      "            cubes.update({mod_name: cube})\n",
      "        else:\n",
      "            log.warning('url {} is probably a timeSeries!'.format(url))\n",
      "    except (RuntimeError, ValueError, MergeError, TimeoutException,\n",
      "            ConstraintMismatchError, CoordinateNotFoundError) as e:\n",
      "        log.warning('Cannot get cube for: {}\\n{}'.format(url, e))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from iris.pandas import as_series\n",
      "\n",
      "from utilities import (standardize_fill_value,\n",
      "                       make_tree, get_nearest_water,\n",
      "                       add_station, ensure_timeseries)\n",
      "\n",
      "\n",
      "for mod_name, cube in cubes.items():\n",
      "    fname = '{:%Y-%m-%d}-{}.nc'.format(stop, mod_name)\n",
      "    fname = os.path.join(directory, fname)\n",
      "    log.info(fmt(' Saving to file {} '.format(fname)))\n",
      "    # NOTE: 2D coords KDtree.  (Iris can only do 1D coords KDtree for now.)\n",
      "    try:\n",
      "        tree, lon, lat = make_tree(cube)\n",
      "    except CoordinateNotFoundError as e:\n",
      "        log.warning('Cannot make KDTree for: {}'.format(mod_name))\n",
      "        continue\n",
      "    # Get model series at observed locations.\n",
      "    raw_series = dict()\n",
      "    for station, obs in observations.iterrows():\n",
      "        try:\n",
      "            kw = dict(k=10, max_dist=0.04, min_var=0.01)\n",
      "            args = cube, tree, obs.lon, obs.lat\n",
      "            series, dist, idx = get_nearest_water(*args, **kw)\n",
      "        except ValueError as e:\n",
      "            log.warning(e)\n",
      "            continue\n",
      "        if not series:\n",
      "            status = \"Found Land\"\n",
      "        else:\n",
      "            raw_series.update({obs['station']: series})\n",
      "            series = as_series(series)\n",
      "            status = \"Found Water\"\n",
      "\n",
      "        log.info('[{}] {}'.format(status, obs.name))\n",
      "\n",
      "    if raw_series:  # Save cube.\n",
      "        for station, cube in raw_series.items():\n",
      "            cube = standardize_fill_value(cube)\n",
      "            cube = add_station(cube, station)\n",
      "        try:\n",
      "            cube = iris.cube.CubeList(raw_series.values()).merge_cube()\n",
      "        except MergeError as e:\n",
      "            log.warning(e)\n",
      "\n",
      "        ensure_timeseries(cube)\n",
      "        iris.save(cube, fname)\n",
      "        del cube\n",
      "\n",
      "    log.info('Finished processing [{}]: {}'.format(mod_name, url))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Load saved files and interpolate to the observations time interval"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from glob import glob\n",
      "from operator import itemgetter\n",
      "\n",
      "from pandas import Panel\n",
      "from utilities import nc2df\n",
      "\n",
      "fname = '{}-OBS_DATA.nc'.format(directory)\n",
      "fname = os.path.join(directory, fname)\n",
      "OBS_DATA = nc2df(fname)\n",
      "index = OBS_DATA.index\n",
      "\n",
      "dfs = dict(OBS_DATA=OBS_DATA)\n",
      "for fname in glob(os.path.join(directory, \"*.nc\")):\n",
      "    if 'OBS_DATA' in fname:\n",
      "        continue\n",
      "    else:\n",
      "        model = fname.split('.')[0].split('-')[-1]\n",
      "        df = nc2df(fname)\n",
      "        kw = dict(method='time', limit=30)\n",
      "        df = df.reindex(index).interpolate(**kw).ix[index]\n",
      "        dfs.update({model: df})\n",
      "\n",
      "dfs = Panel.fromDict(dfs).swapaxes(0, 2)\n",
      "\n",
      "# Clusters.\n",
      "big_list = []\n",
      "for fname in glob(os.path.join(directory, \"*.nc\")):\n",
      "    if 'OBS_DATA' in fname:\n",
      "        continue\n",
      "    nc = iris.load_cube(fname)\n",
      "    model = fname.split('-')[-1].split('.')[0]\n",
      "    lons = nc.coord(axis='X').points\n",
      "    lats = nc.coord(axis='Y').points\n",
      "    stations = nc.coord('station name').points\n",
      "    models = [model]*lons.size\n",
      "    lista = zip(models, lons.tolist(), lats.tolist(), stations.tolist())\n",
      "    big_list.extend(lista)\n",
      "\n",
      "big_list.sort(key=itemgetter(3))\n",
      "df = DataFrame(big_list, columns=['name', 'lon', 'lat', 'station'])\n",
      "df.set_index('station', drop=True, inplace=True)\n",
      "groups = df.groupby(df.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import vincent\n",
      "from utilities import inline_map, make_map\n",
      "\n",
      "ssh = make_map(bbox, line=True, states=False)\n",
      "\n",
      "# ROMS stations files (SABGOM and USEAST?).\n",
      "roms_stations = [(-77.7866, 34.2133),\n",
      "                 (-78.9183, 33.6550),\n",
      "                 (-81.0000, 30.3966),\n",
      "                 (-80.1600, 25.7300),\n",
      "                 (-81.8116, 24.5550),\n",
      "                 (-82.6137, 26.1300),\n",
      "                 (-82.8320, 27.9770),\n",
      "                 (-86.4987, 30.1520)]\n",
      "\n",
      "for station in roms_stations:\n",
      "    location = station[::-1]\n",
      "    popup = '[SABGOM/USEAST]\\nROMS station file'\n",
      "    kw = dict(radius=700, fill_color='red', popup=popup,\n",
      "              fill_opacity=0.75)\n",
      "    ssh.circle_marker(location=location, **kw)\n",
      "\n",
      "\n",
      "# Clusters.\n",
      "for station, info in groups:\n",
      "    station = get_coops_longname(station)\n",
      "    for lat, lon, name in zip(info.lat, info.lon, info.name):\n",
      "        location = lat, lon\n",
      "        popup = '<b>{}</b>\\n{}'.format(station, name)\n",
      "        ssh.simple_marker(location=location, popup=popup,\n",
      "                          clustered_marker=True)\n",
      "\n",
      "# Model and observations.\n",
      "for station in dfs:\n",
      "    sta_name = get_coops_longname(station)\n",
      "    df = dfs[station].dropna(axis=1, how='all')\n",
      "    # FIXME: This is bad!  But I cannot represent NaN with Vega!\n",
      "    df.fillna(value='null', inplace=True)\n",
      "    vis = vincent.Line(df, width=500, height=150)\n",
      "    vis.axis_titles(x='Time', y='Sea surface height (m)')\n",
      "    vis.legend(title=sta_name)\n",
      "    vis.name = sta_name\n",
      "    json = 'station_{}.json'.format(station)\n",
      "    vis.to_json(os.path.join(directory, json))\n",
      "    obs = observations[observations['station'] == station].squeeze()\n",
      "    popup = (vis, json)\n",
      "    if (df.columns == 'OBS_DATA').all():\n",
      "        kw = dict(popup=popup, marker_color=\"blue\", marker_icon=\"ok\")\n",
      "    else:\n",
      "        if 'SABGOM' in df.columns or 'USEAST' in df.columns:\n",
      "            kw = dict(popup=popup, marker_color=\"green\", marker_icon=\"ok-sign\")\n",
      "        else:\n",
      "            kw = dict(popup=popup, marker_color=\"green\", marker_icon=\"ok\")\n",
      "    ssh.simple_marker(location=[obs['lat'], obs['lon']], **kw)\n",
      "\n",
      "# Bad datum.\n",
      "if isinstance(bad_datum, DataFrame):\n",
      "    for station, obs in bad_datum.iterrows():\n",
      "        popup = '<b>Station:</b> {}<br><b>Datum:</b> {}<br>'\n",
      "        popup = popup.format(station, obs['datum'])\n",
      "        kw = dict(popup=popup, marker_color=\"red\", marker_icon=\"question-sign\")\n",
      "        ssh.simple_marker(location=[obs['lat'], obs['lon']], **kw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ssh.create_map(path=os.path.join(directory, 'ssh.html'))\n",
      "inline_map(os.path.join(directory, 'ssh.html'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Compute bias"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utilities import nc2df\n",
      "\n",
      "fname = '{}-OBS_DATA.nc'.format(directory)\n",
      "fname = os.path.join(directory, fname)\n",
      "\n",
      "OBS_DATA = nc2df(fname)\n",
      "index = OBS_DATA.index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from glob import glob\n",
      "from pandas import Panel\n",
      "\n",
      "dfs = dict(OBS_DATA=OBS_DATA)\n",
      "for fname in glob(os.path.join(directory, \"*.nc\")):\n",
      "    if 'OBS_DATA' in fname:\n",
      "        pass\n",
      "    else:\n",
      "        model = fname.split('.')[0].split('-')[-1]\n",
      "        df = nc2df(fname)\n",
      "        if False:\n",
      "            kw = dict(method='time')\n",
      "            df = df.reindex(index).interpolate(**kw).ix[index]\n",
      "        dfs.update({model: df})\n",
      "\n",
      "dfs = Panel.fromDict(dfs).swapaxes(0, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import DataFrame\n",
      "\n",
      "means = dict()\n",
      "for station, df in dfs.iteritems():\n",
      "    df.dropna(axis=1, how='all', inplace=True)\n",
      "    mean = df.mean()\n",
      "    df = df - mean + mean['OBS_DATA']\n",
      "    means.update({station: mean['OBS_DATA'] - mean.drop('OBS_DATA')})\n",
      "\n",
      "bias = DataFrame.from_dict(means).dropna(axis=1, how='all')\n",
      "bias = bias.applymap('{:.2f}'.format).replace('nan', '--')\n",
      "\n",
      "columns = dict()\n",
      "[columns.update({station: get_coops_longname(station)}) for\n",
      " station in bias.columns.values]\n",
      "\n",
      "bias.rename(columns=columns, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = os.path.join(directory, 'bias.html'.format(directory))\n",
      "\n",
      "with open(style, 'r') as f:\n",
      "    css = \"\"\"<style>{}</style>\"\"\".format(f.read())\n",
      "    table = dict(style=css, table=bias.T.to_html())\n",
      "    table = '{style}<div class=\"datagrid\">{table}</div>'.format(**table)\n",
      "\n",
      "with open(fname, 'w') as f:\n",
      "    f.writelines(table)\n",
      "\n",
      "to_html(bias.T, style)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elapsed = time.time() - start_time\n",
      "log.info('{:.2f} minutes'.format(elapsed/60.))\n",
      "log.info('EOF')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}