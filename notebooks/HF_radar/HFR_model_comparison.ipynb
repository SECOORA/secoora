{
 "metadata": {
  "name": "",
  "signature": "sha256:8efc1febf78a5f5ad51786af9fdc1edbd58af3569b422de754335c3b54859ec2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cartopy.io import shapereader\n",
      "\n",
      "kw = dict(resolution='110m', category='cultural',\n",
      "          name='admin_1_states_provinces')\n",
      "shpfilename = shapereader.natural_earth(**kw)\n",
      "\n",
      "reader = shapereader.Reader(shpfilename)\n",
      "states = reader.records()\n",
      "SECOORA = ('North Carolina', 'South Carolina', 'Georgia', 'Florida')\n",
      "for state in states:\n",
      "    name = state.attributes['name']\n",
      "    if name in SECOORA:\n",
      "        print(name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utilities import css_styles\n",
      "css_styles()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### User options are bbox and time range"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from datetime import datetime, timedelta\n",
      "\n",
      "# SECOORA: NC, SC GA, FL\n",
      "bounding_box_type = \"box\"\n",
      "bounding_box = [-87.4, 24.25, -74.7, 36.70]\n",
      "\n",
      "# Temporal range.\n",
      "jd_now = datetime.utcnow().replace(minute=0, second=0, microsecond=0)\n",
      "jd_start,  jd_stop = jd_now - timedelta(hours=(6)), jd_now\n",
      "\n",
      "print('%s, %s ' % (jd_start,  jd_stop))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### CSW Search NGDC Geoportal"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from owslib import fes\n",
      "from owslib.csw import CatalogueServiceWeb\n",
      "\n",
      "from utilities import date_range\n",
      "from ipy_table import make_table, apply_theme\n",
      "\n",
      "def fes_filter(jd_start, jd_stop, bounding_box, data_dict):\n",
      "    \"\"\"Convert User Input into FES filters.\"\"\"\n",
      "    time_fmt = '%Y-%m-%d %H:%M'\n",
      "    start, stop = date_range(jd_start.strftime(time_fmt),\n",
      "                             jd_stop.strftime(time_fmt))\n",
      "    bbox = fes.BBox(bounding_box)\n",
      "    # Use the search name to create search filter.\n",
      "    kw = dict(propertyname='apiso:AnyText', escapeChar='\\\\',\n",
      "              wildCard='*', singleChar='?')\n",
      "    or_filt = fes.Or([fes.PropertyIsLike(literal=('*%s*' % val), **kw) for\n",
      "                      val in data_dict['currents']['names']])\n",
      "    \n",
      "    val = 'Averages'\n",
      "    not_filt = fes.Not([fes.PropertyIsLike(literal=('*%s*' % val), **kw)])\n",
      "    \n",
      "    filter_list = [fes.And([bbox, start, stop, or_filt, not_filt])]\n",
      "    return filter_list\n",
      "    \n",
      "# CF and SOS names.\n",
      "data_dict = dict()\n",
      "sos_name = 'Currents'\n",
      "# FIXME: Add model names\n",
      "data_dict['currents'] = {\"names\": ['currents',\n",
      "                                   'surface_eastward_sea_water_velocity',\n",
      "                                   '*surface_eastward_sea_water_velocity*'],\n",
      "                         \"sos_name\": ['currents']}  # <- TODOL Check why sos_name is here!\n",
      "\n",
      "# Catalog.\n",
      "endpoint = 'http://www.ngdc.noaa.gov/geoportal/csw'\n",
      "csw = CatalogueServiceWeb(endpoint, timeout=60)\n",
      "filter_list = fes_filter(jd_start, jd_stop, bounding_box, data_dict)\n",
      "csw.getrecords2(constraints=filter_list, maxrecords=1000, esn='full')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Found {} csw records:\\n\".format(len(csw.records)))\n",
      "\n",
      "table = [(item.title, rec) for rec, item in csw.records.items()]\n",
      "table.insert(0, ('Title', 'Record'))\n",
      "make_table(table)\n",
      "apply_theme('basic')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### DAP"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utilities import service_urls\n",
      "\n",
      "dap_urls = service_urls(csw.records, service='odp:url')\n",
      "dap_urls = sorted(set(dap_urls))\n",
      "print(\"Total DAP: %s\" % len(dap_urls))\n",
      "print(\"\\n\".join(dap_urls))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### SOS"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sos_urls = service_urls(csw.records, service='sos:url')\n",
      "sos_urls = sorted(set(sos_urls))\n",
      "print(\"Total SOS: %s\" % len(sos_urls))\n",
      "print(\"\\n\".join(sos_urls))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Update SOS time-date"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iso_start = jd_start.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
      "iso_end = jd_stop.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
      "print('{}\\n{}'.format(iso_start, iso_end))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"success\"><strong>Get list of stations</strong>\n",
      "- we get a list of the available stations from NOAA and COOPS</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Get CO-OPS Station Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyoos.collectors.coops.coops_sos import CoopsSos\n",
      "\n",
      "coops_collector = CoopsSos()\n",
      "coops_collector.start_time = jd_start\n",
      "coops_collector.end_time = jd_stop\n",
      "coops_collector.variables = data_dict[\"currents\"][\"sos_name\"]\n",
      "coops_collector.server.identification.title\n",
      "\n",
      "ofrs = coops_collector.server.offerings\n",
      "\n",
      "print(\"{}\\n{}\".format(coops_collector.start_time,\n",
      "                      coops_collector.end_time))\n",
      "print(len(ofrs))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Gets a list of the active stations from coops"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import read_csv\n",
      "from utilities import sos_request\n",
      "\n",
      "params = dict(observedProperty=sos_name,\n",
      "              featureOfInterest='BBOX:{0},{1},{2},{3}'.format(*bounding_box))\n",
      "\n",
      "url = sos_request(url='http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS', **params)\n",
      "obs_loc_df = read_csv(url)\n",
      "obs_loc_df.drop_duplicates(subset='station_id', inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cols = ['processing_level',\n",
      "        'reporting_interval (s)',\n",
      "        'sea_water_temperature (C)',\n",
      "        'platform_roll_angle (degree)',\n",
      "        'platform_orientation (degree)',\n",
      "        'platform_pitch_angle (degree)',\n",
      "        'orientation', 'sampling_rate (Hz)',\n",
      "        'bin_size (m)', 'first_bin_center (m)',\n",
      "        'direction_of_sea_water_velocity (degree)',\n",
      "        'sea_water_speed (cm/s)', 'sensor_depth (m)',\n",
      "        'number_of_bins', 'bin (count)', 'bin_distance (m)']\n",
      "obs_loc_df.drop(cols, axis=1, inplace=True)\n",
      "\n",
      "make_table(np.r_[obs_loc_df.columns[None, :], obs_loc_df.values])\n",
      "apply_theme('basic')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Get NDBC Station Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyoos.collectors.ndbc.ndbc_sos import NdbcSos\n",
      "\n",
      "ndbc_collector = NdbcSos()\n",
      "ndbc_collector.start_time = jd_start\n",
      "ndbc_collector.end_time = jd_stop\n",
      "ndbc_collector.variables = data_dict[\"currents\"][\"sos_name\"]\n",
      "ndbc_collector.server.identification.title\n",
      "ofrs = ndbc_collector.server.offerings\n",
      "\n",
      "print(\"{}\\n{}\".format(ndbc_collector.start_time,\n",
      "                      ndbc_collector.end_time))\n",
      "print(len(ofrs))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params = dict(offering='urn:ioos:network:noaa.nws.ndbc:all',\n",
      "              observedProperty=sos_name,\n",
      "              featureOfInterest='BBOX:{0},{1},{2},{3}'.format(*bounding_box))\n",
      "\n",
      "url = sos_request(url='http://sdf.ndbc.noaa.gov/sos/server.php', **params)\n",
      "obs_loc_df = read_csv(url)\n",
      "obs_loc_df.drop_duplicates(subset='station_id', inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "obs_loc_df.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cols = ['sea_water_speed (cm/s)',\n",
      "        'bin (count)', 'depth (m)',\n",
      "        'sea_water_temperature (C)',\n",
      "        'platform_roll_angle (degree)',\n",
      "        'echo_intensity_beam1 (count)',\n",
      "        'echo_intensity_beam2 (count)',\n",
      "        'echo_intensity_beam3 (count)',\n",
      "        'echo_intensity_beam4 (count)',\n",
      "        'platform_pitch_angle (degree)',\n",
      "        'platform_orientation (degree)',\n",
      "        'pct_rejected (%)', 'pct_bad (%)',\n",
      "        'upward_sea_water_velocity (cm/s)',\n",
      "        'correlation_magnitude_beam1 (count)',\n",
      "        'correlation_magnitude_beam2 (count)',\n",
      "        'correlation_magnitude_beam3 (count)',\n",
      "        'correlation_magnitude_beam4 (count)',\n",
      "        'error_velocity (cm/s)', 'quality_flags',\n",
      "        'direction_of_sea_water_velocity (degree)',\n",
      "        'pct_good_3_beam (%)', 'pct_good_4_beam (%)']\n",
      "\n",
      "obs_loc_df.drop(cols, axis=1, inplace=True)\n",
      "\n",
      "make_table(np.r_[obs_loc_df.columns[None, :], obs_loc_df.values])\n",
      "apply_theme('basic')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### NDBC Station information"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "import os\n",
      "import folium\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from utilities import service_urls, get_coordinates, inline_map, processStationInfo, get_ncfiles_catalog\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### The function only support who date time differences"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"error\">\n",
      "<strong>Large Temporal Requests Need To Be Broken Down</strong> -\n",
      "When requesting a large temporal range outside the SOS limit, the sos\n",
      "request needs to be broken down.  See issues in\n",
      "[ioos](https://github.com/ioos/system-test/issues/81),\n",
      "[ioos](https://github.com/ioos/system-test/issues/101),\n",
      "[ioos](https://github.com/ioos/system-test/issues/116)\n",
      "and\n",
      "[pyoos](https://github.com/ioos/pyoos/issues/35).  Unfortunately currents\n",
      "is not available via DAP\n",
      "([ioos](https://github.com/ioos/system-test/issues/116))</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"error\">\n",
      "<strong>Large Temporal Requests Need To Be Broken Down</strong> -\n",
      "Obtaining long time series from COOPS via SOS is not ideal and the opendap\n",
      "links are not available, so we use the tides and currents api to get the\n",
      "currents in json format. The api response provides in default bin, unless a\n",
      "bin is specified (i.e bin=1)</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"warning\"><strong>Pyoos</strong> -\n",
      "Should be able to use the collector, but does not work?</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"info\">\n",
      "<strong>Use NDBC DAP endpoints to get time-series data</strong> -\n",
      "The DAP server for currents is available for NDBC data, we use that\n",
      "to get long time series data.</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"info\"><strong>Progress Information For Large Requests</strong> -\n",
      "Shows the user a progress bar for each stations as its processed.  Click\n",
      "[here]('http://www.tidesandcurrents.noaa.gov/cdata/StationList?type=Current+Data&filter=active')\n",
      "to show more information on the CO-OPS locations</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"error\"><strong>Processing long time series</strong> -\n",
      "The CO-OPS Server responds really slow (> 30 secs, for what should be\n",
      "a 5 sec request) to multiple requests, so getting long time series\n",
      "data is almost impossible.</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### get CO-OPS station data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Used to define the number of days allowable by the service.\n",
      "coops_point_max_days = ndbc_point_max_days = 30\n",
      "print(\"start & end dates: %s, %s\\n\" % (jd_start, jd_stop))\n",
      "\n",
      "for station_index in st_list.keys():\n",
      "    # Set it so we can use it later.\n",
      "    st = station_index.split(\":\")[-1]\n",
      "    print('[%s]: %s' % (st_list[station_index]['source'], station_index))\n",
      "\n",
      "    if st_list[station_index]['source'] == 'coops':\n",
      "        # Coops fails for large requests.\n",
      "        master_df = []\n",
      "    elif st_list[station_index]['source'] == 'ndbc':\n",
      "        # Use the dap catalog to get the data.\n",
      "        master_df = get_ncfiles_catalog(station_index, jd_start, jd_stop)\n",
      "    if len(master_df) > 0:\n",
      "        st_list[station_index]['hasObsData'] = True\n",
      "    st_list[station_index]['obsData'] = master_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Check theres data in there.\n",
      "st_list[st_list.keys()[2]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Plot the pandas data frames for the stations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"error\"><strong>Station Data Plot</strong> -\n",
      "There might be an issue with some of the NDBC station data...</div>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for station_index in st_list.keys():\n",
      "    df = st_list[station_index]['obsData']\n",
      "    if len(df) > 1:\n",
      "        st_list[station_index]['hasObsData'] = True\n",
      "        print(\"num rows: %s\" % len(df))\n",
      "        fig = plt.figure(figsize=(18, 3))\n",
      "        plt.scatter(df.index, df['sea_water_speed (cm/s)'])\n",
      "        fig.suptitle('Station:'+station_index, fontsize=20)\n",
      "        plt.xlabel('Date', fontsize=18)\n",
      "        plt.ylabel('sea_water_speed (cm/s)', fontsize=16)\n",
      "    else:\n",
      "        st_list[station_index]['hasObsData'] = False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Find the min and max data values"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"warning\"><strong>Station Data Plot</strong> -\n",
      "Some stations might not plot due to the data.</div>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build current roses.\n",
      "filelist = [f for f in os.listdir(\"./images\") if f.endswith(\".png\")]\n",
      "for f in filelist:\n",
      "    os.remove(\"./images/\"+f)\n",
      "\n",
      "station_min_max = {}\n",
      "for station_index in st_list.keys():\n",
      "    all_spd_data = {}\n",
      "    all_dir_data = {}\n",
      "    all_time_spd = []\n",
      "    all_time_dir = []\n",
      "    df = st_list[station_index]['obsData']\n",
      "    if len(df) > 1:\n",
      "        try:\n",
      "            spd_data = df['sea_water_speed (cm/s)'].values\n",
      "            spd_data = np.array(spd_data)\n",
      "\n",
      "            dir_data = df['direction_of_sea_water_velocity (degree)'].values\n",
      "            dir_data = np.array(dir_data)\n",
      "\n",
      "            time_data = df.index.tolist()\n",
      "            time_data = np.array(time_data)\n",
      "\n",
      "            for idx in range(0, len(spd_data)):\n",
      "                if spd_data[idx] > 998:\n",
      "                    continue\n",
      "                elif np.isnan(spd_data[idx]):\n",
      "                    continue\n",
      "                elif dir_data[idx] == 0:\n",
      "                    continue\n",
      "                else:\n",
      "                    dt_year = time_data[idx].year\n",
      "                    dt_year = str(dt_year)\n",
      "                    if dt_year not in all_spd_data.keys():\n",
      "                        all_spd_data[dt_year] = []\n",
      "                        all_dir_data[dt_year] = []\n",
      "                    # Convert to knots.\n",
      "                    knot_val = (spd_data[idx] * 0.0194384449)\n",
      "                    knot_val = \"%.4f\" % knot_val\n",
      "                    knot_val = float(knot_val)\n",
      "\n",
      "                    all_spd_data[dt_year].append(knot_val)\n",
      "                    all_dir_data[dt_year].append(dir_data[idx])\n",
      "\n",
      "                    all_time_spd.append(knot_val)\n",
      "                    all_time_dir.append(dir_data[idx])\n",
      "\n",
      "            all_time_spd = np.array(all_time_spd, dtype=np.float)\n",
      "            all_time_dir = np.array(all_time_dir, dtype=np.float)\n",
      "\n",
      "            station_min_max[station_index] = {}\n",
      "            for year in all_spd_data.keys():\n",
      "                year_spd = np.array(all_spd_data[year])\n",
      "                year_dir = np.array(all_dir_data[year])\n",
      "                station_min_max[station_index][year] = {}\n",
      "                station_min_max[station_index][year]['pts'] = len(year_spd)\n",
      "                min_spd, max_spd = np.min(year_spd), np.max(year_spd)\n",
      "                station_min_max[station_index][year]['spd_min'] = min_spd\n",
      "                station_min_max[station_index][year]['spd_max'] = max_spd\n",
      "                dir_min, dir_max = np.argmin(year_spd), np.argmax(year_spd)\n",
      "                yr_dir_min, yr_dir_max = year_dir[dir_min], year_dir[dir_max]\n",
      "                station_min_max[station_index][year]['dir_at_min'] = yr_dir_min\n",
      "                station_min_max[station_index][year]['dir_at_max'] = yr_dir_max\n",
      "            try:\n",
      "                # A stacked histogram with normed\n",
      "                # (displayed in percent) results.\n",
      "                ax = new_axes()\n",
      "                ax.set_title(station_index.split(\":\")[-1] +\n",
      "                             \" stacked histogram with normed (displayed in %)\"\n",
      "                             \"\\nresults (spd in knots), All Time.\")\n",
      "                ax.bar(all_time_dir, all_time_spd, normed=True,\n",
      "                       opening=0.8, edgecolor='white')\n",
      "                set_legend(ax)\n",
      "\n",
      "                fig = plt.gcf()\n",
      "                fig.set_size_inches(8, 8)\n",
      "                fname = './images/%s.png' % station_index.split(\":\")[-1]\n",
      "                fig.savefig(fname, dpi=100)\n",
      "            except Exception as e:\n",
      "                print(\"Error when plotting %s\" % e)\n",
      "                pass\n",
      "\n",
      "        except Exception as e:  # Be specific here!\n",
      "            print(\"Error: %s\" % e)\n",
      "            pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the min and max from each station.\n",
      "fields = ['spd_']\n",
      "\n",
      "for idx in range(0, len(fields)):\n",
      "    d_field = fields[idx]\n",
      "    fig, ax = plt.subplots(1, 1, figsize=(18, 5))\n",
      "    for st in station_min_max:\n",
      "        x = y_min = y_max = []\n",
      "        for year in station_min_max[st]:\n",
      "            x.append(year)\n",
      "            y_max.append(station_min_max[st][year][d_field+'max'])\n",
      "        marker_size = station_min_max[st][year]['pts'] / 80\n",
      "        marker_size += 20\n",
      "        station_label = st.split(\":\")[-1]\n",
      "\n",
      "        ax.scatter(np.array(x), np.array(y_max),\n",
      "                   label=station_label, s=marker_size,\n",
      "                   c=np.random.rand(3, 1), marker=\"o\")\n",
      "        ax.set_xlim([2000, 2015])\n",
      "        ax.set_title(\"Yearly Max Speed Per Station, Marker Scaled Per\"\n",
      "                     \"Annual Pts (bigger = more pts per year)\")\n",
      "        ax.set_ylabel(\"speed (knots)\")\n",
      "        ax.set_xlabel(\"Year\")\n",
      "        ax.legend(loc='upper left')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Produce Interactive Map"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "station = st_list[st_list.keys()[0]]\n",
      "m = folium.Map(location=[station[\"lat\"], station[\"lon\"]], zoom_start=4)\n",
      "m.line(get_coordinates(bounding_box, bounding_box_type),\n",
      "       line_color='#FF0000', line_weight=5)\n",
      "\n",
      "# Plot the obs station.\n",
      "for st in st_list:\n",
      "    hasObs = st_list[st]['hasObsData']\n",
      "    if hasObs:\n",
      "        fname = './images/%s.png' % st.split(\":\")[-1]\n",
      "        if os.path.isfile(fname):\n",
      "            popup = ('Obs Location:<br>%s<br><img border=120 src=\"'\n",
      "                     './images/%s.png\" width=\"242\" height=\"242\">' %\n",
      "                     (st, st.split(\":\")[-1]))\n",
      "            m.simple_marker([st_list[st][\"lat\"], st_list[st][\"lon\"]],\n",
      "                            popup=popup,\n",
      "                            marker_color=\"green\",\n",
      "                            marker_icon=\"ok\")\n",
      "        else:\n",
      "            popup = 'Obs Location:<br>%s' % st\n",
      "            m.simple_marker([st_list[st][\"lat\"], st_list[st][\"lon\"]],\n",
      "                            popup=popup,\n",
      "                            marker_color=\"green\",\n",
      "                            marker_icon=\"ok\")\n",
      "    else:\n",
      "        popup = 'Obs Location:<br>%s' % st\n",
      "        m.simple_marker([st_list[st][\"lat\"], st_list[st][\"lon\"]],\n",
      "                        popup=popup,\n",
      "                        marker_color=\"red\",\n",
      "                        marker_icon=\"remove\")\n",
      "inline_map(m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def new_axes():\n",
      "    fig = plt.figure(figsize=(8, 8), dpi=80, facecolor='w', edgecolor='w')\n",
      "    rect = [0.1, 0.1, 0.8, 0.8]\n",
      "    ax = WindroseAxes(fig, rect, axisbg='w')\n",
      "    fig.add_axes(ax)\n",
      "    return ax\n",
      "\n",
      "\n",
      "def set_legend(ax):\n",
      "    \"\"\"Adjust the legend box.\"\"\"\n",
      "    l = ax.legend()\n",
      "    plt.setp(l.get_texts(), fontsize=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}